<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: algorithm | Hujiawei Bujidao]]></title>
  <link href="http://hujiaweibujidao.github.io/blog/categories/algorithm/atom.xml" rel="self"/>
  <link href="http://hujiaweibujidao.github.io/"/>
  <updated>2014-05-10T21:55:31+08:00</updated>
  <id>http://hujiaweibujidao.github.io/</id>
  <author>
    <name><![CDATA[hujiawei]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - Trees]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/08/python-algorithms-Trees/"/>
    <updated>2014-05-08T20:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/08/python-algorithms-Trees</id>
    <content type="html"><![CDATA[<p>参考内容：</p>

<p>1.<a href="http://interactivepython.org/courselib/static/pythonds/index.html">Problem Solving with Python</a></p>

<p>Chapter 6 Trees and Tree Algorithms   </p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<h4 id="section">树的总结</h4>

<p>1.二叉搜索树 <a href="http://zh.wikipedia.org/wiki/%E4%BA%8C%E5%85%83%E6%90%9C%E5%B0%8B%E6%A8%B9">on_wiki</a>：一种特殊的二叉树，它满足下面的性质：任何一个节点的key值都比它左子树上的节点的key值要大，但是比它右子树上的节点的key值要小。节点查找，插入，删除等操作的时间复杂度都是$O(n)$</p>

<p>难点在于删除节点的操作(下面摘自wiki)：</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bst_del_wiki.png" alt="image" /></p>

<p><strong>引用开始</strong> [一份不错的讲解<a href="http://www.cnblogs.com/Anker/archive/2013/01/28/2880581.html">来自博客园</a>]</p>

<hr />

<p>1.在二叉查找树中找某个节点的前驱和后继节点</p>

<p>给定一个二叉查找树中的结点，找出在中序遍历顺序下某个节点的前驱和后继。如果树中所有关键字都不相同，则某一结点x的前驱就是小于key[x]的所有关键字中最大的那个结点，后继即是大于key[x]中的所有关键字中最小的那个结点。根据二叉查找树的结构和性质，不用对关键字做任何比较，就可以找到某个结点的前驱和后继。</p>

<p>查找前驱步骤：先判断x是否有左子树，如果有则在left[x]中查找关键字最大的结点，即是x的前驱。如果没有左子树，则从x继续向上执行此操作，直到遇到某个结点是其父节点的右孩子结点，<strong>此时该父节点就是前驱</strong>。例如下图查找结点7的前驱结点6过程：</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bst_pre.png" alt="image" /></p>

<p>伪代码</p>

<p><code>cpp
TREE_SUCCESSOR(x)
    if right[x] != NULL
        then return TREE_MINMUM(right(x))
    y=parent[x]
    while y!= NULL and x ==left[y]
           do x = y
              y=parent[y]
    return y
</code></p>

<p>查找后继步骤：先判断x是否有右子树，如果有则在right[x]中查找关键字最小的结点，即使x的后继。如果没有右子树，则从x的父节点开始向上查找，直到遇到某个结点是其父结点的左儿子的结点时为止，<strong>此时该父节点就是后继</strong>。例如下图查找结点13的后继结点15的过程：</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bst_later.png" alt="image" /></p>

<p>伪代码</p>

<p><code>cpp
TREE_PROCESSOR(x)
    if right[x] != NULL
        then return TREE_MINMUM(right(x))
    y=parent[x]
    while y!= NULL and x ==right[y]
           do x = y
              y=parent[y]
    return y
</code></p>

<p>2.删除节点操作</p>

<p>(1)结点z没有左右子树，则修改其父节点p[z]，<strong>删除父节点对它的链接</strong>。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bst_del1.png" alt="image" /></p>

<p>(2)如果结点z只有一个子树（左子树或者右子树），通过在其子结点与父节点建立一条链接来删除z。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bst_del2.png" alt="image" /></p>

<p>(3)如果z有两个子女，则先删除z的后继y(y没有左孩子)，再用y的内容来替代z的内容。</p>

<p><strong>[博主提示：这里找到z的后继就是利用上面的查找后继的方法，根据wiki也可以是用z的前驱来替换。另外，删除后继和替换内容的操作其实也可以反过来，保证数据不丢失就行了]</strong></p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bst_del3.png" alt="image" /></p>

<hr />

<p><strong>引用结束</strong></p>

<p><a href="http://zh.wikipedia.org/wiki/%E4%BA%8C%E5%85%83%E6%90%9C%E5%B0%8B%E6%A8%B9">wiki</a>上的python代码实现节点删除操作，比后面的python代码更加简洁易懂</p>

<p>代码采用了递归的形式处理，相当于只需要考虑了要删除的节点就在当前位置该如何处理，然后，对于只有左孩子节点或者只有右孩子结点或者没有孩子节点的情况直接进行节点覆盖就行了，但是，对于复杂的第三种情况，在左右孩子节点都存在的情况下，只需从它的右孩子结点中找到最小的那个元素即为要删除节点的后继(同理，可以找到左孩子结点中找到最大的那个元素，即为要删除节点的前驱)，然后复制后继节点中的内容到要删除的节点，最后删除后继节点即可。</p>

<p>```python
def find_min(self):   # Gets minimum node (leftmost leaf) in a subtree
    current_node = self
    while current_node.left_child:
        current_node = current_node.left_child
    return current_node</p>

<p>def replace_node_in_parent(self, new_value=None):
    if self.parent:
        if self == self.parent.left_child:
            self.parent.left_child = new_value
        else:
            self.parent.right_child = new_value
    if new_value:
        new_value.parent = self.parent</p>

<p>def binary_tree_delete(self, key):
    if key &lt; self.key:
        self.left_child.binary_tree_delete(key)
    elif key &gt; self.key:
        self.right_child.binary_tree_delete(key)
    else: # delete the key here
        if self.left_child and self.right_child: # if both children are present
            successor = self.right_child.find_min()
            self.key = successor.key
            successor.binary_tree_delete(successor.key)
        elif self.left_child:   # if the node has only a <em>left</em> child
            self.replace_node_in_parent(self.left_child)
        elif self.right_child:  # if the node has only a <em>right</em> child
            self.replace_node_in_parent(self.right_child)
        else: # this node has no children
            self.replace_node_in_parent(None)
```</p>

<p>参考内容1中在第三种情况下使用的是wiki中的第二种方案，并且是使用直接后继来代替要删除的节点。</p>

<p>二叉查找树的python完整实现见下面AVL树的完整实现(除去AVLTree即可)[参考内容1中的代码相当冗余，但是可读性蛮好，个人认为如果要实现删除节点操作的话建议参考wiki上python代码的实现，也可以查看参考内容1中对代码的详细解释加深理解]</p>

<p>如果原始的列表是基本有序的，那么得到的二叉树会变成一个扭曲的二叉树，性能就相当于一个链表了。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bst_worst.png" alt="image" /></p>

<p>8.平衡二叉查找树：为了避免得到前面提到的扭曲的二叉查找树，于是就有了平衡二叉查找树的概念。</p>

<p>AVL树是最先发明的平衡二叉树，它得名于它的发明者G.M. Adelson-Velsky和E.M. Landis，他们在1962年的论文《An algorithm for the organization of information》中发表了它。</p>

<p><a href="http://zh.wikipedia.org/wiki/AVL%E6%A0%91">on_wiki</a></p>

<p>AVL树的基本操作的实现</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/avl_operations.png" alt="image" /></p>

<p>如何进行旋转</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/avl_rotate.png" alt="image" /></p>

<p>旋转的实现描述</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/avl_rotatedetails.png" alt="image" /></p>

<p><a href="http://zhuyanfeng.com/archives/743">这篇文章对AVL树的讲解很好，并使用C++语言进行实现</a>以及<a href="http://zhuyanfeng.com/archives/716">另一篇文章</a></p>

<p><a href="http://interactivepython.org/courselib/static/pythonds/Trees/balanced.html">参考内容1关于AVL树的讲解</a> —&gt; <a href="http://hujiaweibujidao.github.io/files/avltree.pdf">如果访问较慢可以点击这里下载</a></p>

<p>(1)平衡因子：左子树与右子树的高度之差</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/avl_bf.png" alt="image" /></p>

<p>(2)分析为什么AVL树能够对查找，插入，删除操作都达到$O(logn)$的效率</p>

<p>推理当中关于斐波那契数列在N很大的时候后项与前项之商接近黄金分割比的内容可参见<a href="http://zh.wikipedia.org/wiki/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B8">斐波那契数列on_wiki</a></p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/avl1.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/201405/avl2.png" alt="image" /></p>

<p>(3)左旋，右旋以及左右旋和右左旋</p>

<p>左旋：如果新的根节点有左孩子结点，那么左孩子结点就成为原来的根节点的右孩子结点</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/avl_left.png" alt="image" /></p>

<p>右旋：如果新的根节点有右孩子结点，那么右孩子结点就成为原来的根节点的左孩子结点</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/avl_right.png" alt="image" /></p>

<p>一种特殊的情况，单一的左旋和右旋都不行，不停地重复交替，所以需要左右旋(或者右左旋)</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/avl_leftright.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/201405/avl_leftright2.png" alt="image" /></p>

<p>(4)如何在不重新计算子树的高度情况下修改旋转前的根节点和旋转后的根节点的平衡因子值</p>

<p>下面是左旋的例子</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/avl_rebal1.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/201405/avl_rebal2.png" alt="image" /></p>

<p>python代码实现[参考内容1未给出完整代码，下面代码是我自己补充的，添加了测试，如果有误请回复我]</p>

<p>```
class TreeNode:
    def <strong>init</strong>(self,key,val,left=None,right=None,parent=None,balanceFactor=0):
        self.key = key
        self.payload = val
        self.leftChild = left
        self.rightChild = right
        self.parent = parent
        self.balanceFactor=balanceFactor; #default new node balance factor is 0</p>

<pre><code>def hasLeftChild(self):
    return self.leftChild

def hasRightChild(self):
    return self.rightChild

def isLeftChild(self):
    return self.parent and self.parent.leftChild == self

def isRightChild(self):
    return self.parent and self.parent.rightChild == self

def isRoot(self):
    return not self.parent

def isLeaf(self):
    return not (self.rightChild or self.leftChild)

def hasAnyChildren(self):
    return self.rightChild or self.leftChild

def hasBothChildren(self):
    return self.rightChild and self.leftChild

def replaceNodeData(self,key,value,lc,rc):
    self.key = key
    self.payload = value
    self.leftChild = lc
    self.rightChild = rc
    if self.hasLeftChild():
        self.leftChild.parent = self
    if self.hasRightChild():
        self.rightChild.parent = self
</code></pre>

<p>class BinarySearchTree:</p>

<pre><code>def __init__(self):
    self.root = None
    self.size = 0

def length(self):
    return self.size

def __len__(self):
    return self.size

def inorder(self,node):
    if node.leftChild:
        self.inorder(node.leftChild)
    self.print_node(node)
    if node.rightChild:
        self.inorder(node.rightChild)

def levelorder(self,node):
    nodes = []
    nodes.append(node)
    while len(nodes)&gt;0:
        current_node = nodes.pop(0)
        self.print_node(current_node)
        if current_node.leftChild:
            nodes.append(current_node.leftChild)
        if current_node.rightChild:
            nodes.append(current_node.rightChild)

def print_node(self,node):
    if node.parent:
        print([node.key,node.payload,node.parent.key])
    else:
        print([node.key,node.payload])

def put(self,key,val):
    if self.root:
        self._put(key,val,self.root)
    else:
        self.root = TreeNode(key,val)
    self.size = self.size + 1

def _put(self,key,val,currentNode):
    if key &lt; currentNode.key:
        if currentNode.hasLeftChild():
            self._put(key,val,currentNode.leftChild)
        else:
            currentNode.leftChild = TreeNode(key,val,parent=currentNode)
    else:
        if currentNode.hasRightChild():
            self._put(key,val,currentNode.rightChild)
        else:
            currentNode.rightChild = TreeNode(key,val,parent=currentNode)

def __setitem__(self,k,v):
    self.put(k,v)

def get(self,key):
    if self.root:
        res = self._get(key,self.root)
        if res:
            return res.payload
        else:
            return None
    else:
        return None

def _get(self,key,currentNode):
    if not currentNode:
        return None
    elif currentNode.key == key:
        return currentNode
    elif key &lt; currentNode.key:
        return self._get(key,currentNode.leftChild)
    else:
        return self._get(key,currentNode.rightChild)

def __getitem__(self,key):
    return self.get(key)

def __contains__(self,key):
    if self._get(key,self.root):
        return True
    else:
        return False

def delete(self,key):
    if self.size &gt; 1:
        nodeToRemove = self._get(key,self.root)
        if nodeToRemove:
            self.remove(nodeToRemove)
            self.size = self.size-1
        else:
            raise KeyError('Error, key not in tree')
    elif self.size == 1 and self.root.key == key:
        self.root = None
        self.size = self.size - 1
    else:
        raise KeyError('Error, key not in tree')

def __delitem__(self,key):
    self.delete(key)

def spliceOut(self):
    if self.isLeaf():
        if self.isLeftChild():
            self.parent.leftChild = None
        else:
            self.parent.rightChild = None
    elif self.hasAnyChildren():
        if self.hasLeftChild():
            if self.isLeftChild():
                self.parent.leftChild = self.leftChild
            else:
                self.parent.rightChild = self.leftChild
            self.leftChild.parent = self.parent
        else:
            if self.isLeftChild():
                self.parent.leftChild = self.rightChild
            else:
                self.parent.rightChild = self.rightChild
            self.rightChild.parent = self.parent

def findSuccessor(self):
    succ = None
    if self.hasRightChild():
        succ = self.rightChild.findMin()
    else:
        if self.parent:
            if self.isLeftChild():
                succ = self.parent
            else:
                self.parent.rightChild = None
                succ = self.parent.findSuccessor()
                self.parent.rightChild = self
    return succ

def findMin(self):
    current = self
    while current.hasLeftChild():
        current = current.leftChild
    return current

def remove(self,currentNode):
    if currentNode.isLeaf(): #leaf
        if currentNode == currentNode.parent.leftChild:
            currentNode.parent.leftChild = None
        else:
            currentNode.parent.rightChild = None
    elif currentNode.hasBothChildren(): #interior
        succ = currentNode.findSuccessor()
        succ.spliceOut()
        currentNode.key = succ.key
        currentNode.payload = succ.payload
    else: # this node has one child
        if currentNode.hasLeftChild():
            if currentNode.isLeftChild():
                currentNode.leftChild.parent = currentNode.parent
                currentNode.parent.leftChild = currentNode.leftChild
            elif currentNode.isRightChild():
                currentNode.leftChild.parent = currentNode.parent
                currentNode.parent.rightChild = currentNode.leftChild
            else:
                currentNode.replaceNodeData(currentNode.leftChild.key,
                                            currentNode.leftChild.payload,
                                            currentNode.leftChild.leftChild,
                                            currentNode.leftChild.rightChild)
        else:
            if currentNode.isLeftChild():
                currentNode.rightChild.parent = currentNode.parent
                currentNode.parent.leftChild = currentNode.rightChild
            elif currentNode.isRightChild():
                currentNode.rightChild.parent = currentNode.parent
                currentNode.parent.rightChild = currentNode.rightChild
            else:
                currentNode.replaceNodeData(currentNode.rightChild.key,
                                            currentNode.rightChild.payload,
                                            currentNode.rightChild.leftChild,
                                            currentNode.rightChild.rightChild)
</code></pre>

<p>class AVLTree(BinarySearchTree):</p>

<pre><code># def put(self,key,val):
#     if self.root:
#         self._put(key,val,self.root)
#     else:
#         self.root = TreeNode(key,val)
#         self.root.balanceFactor = 0
#     self.size = self.size + 1

def _put(self,key,val,currentNode):
    if key &lt; currentNode.key:
        if currentNode.hasLeftChild():
            self._put(key,val,currentNode.leftChild)
        else:
            currentNode.leftChild = TreeNode(key,val,parent=currentNode)
            self.updateBalance(currentNode.leftChild)
    else:
        if currentNode.hasRightChild():
            self._put(key,val,currentNode.rightChild)
        else:
            currentNode.rightChild = TreeNode(key,val,parent=currentNode)
            self.updateBalance(currentNode.rightChild)

def updateBalance(self,node):
    if node.balanceFactor &gt; 1 or node.balanceFactor &lt; -1:
        self.rebalance(node)
        return
    if node.parent != None:
        if node.isLeftChild():
            node.parent.balanceFactor += 1
        elif node.isRightChild():
            node.parent.balanceFactor -= 1
        if node.parent.balanceFactor != 0:
            self.updateBalance(node.parent)

def rotateLeft(self,rotRoot): #rotate left
    newRoot = rotRoot.rightChild
    rotRoot.rightChild = newRoot.leftChild
    if newRoot.leftChild != None:
        newRoot.leftChild.parent = rotRoot
    newRoot.parent = rotRoot.parent
    if rotRoot.isRoot():
        self.root = newRoot
    else:
        if rotRoot.isLeftChild():
            rotRoot.parent.leftChild = newRoot
        else:
            rotRoot.parent.rightChild = newRoot
    newRoot.leftChild = rotRoot
    rotRoot.parent = newRoot
    rotRoot.balanceFactor = rotRoot.balanceFactor + 1 - min(newRoot.balanceFactor, 0)
    newRoot.balanceFactor = newRoot.balanceFactor + 1 + max(rotRoot.balanceFactor, 0)

def rotateRight(self,rotRoot): #rotate right
    newRoot = rotRoot.leftChild
    rotRoot.leftChild = newRoot.rightChild # deal child
    if newRoot.rightChild != None:
        newRoot.rightChild.parent = rotRoot #deal child parent
    newRoot.parent = rotRoot.parent #deal root parent
    if rotRoot.isRoot():
        self.root = newRoot
    else:
        if rotRoot.isLeftChild():
            rotRoot.parent.leftChild = newRoot
        else:
            rotRoot.parent.rightChild = newRoot
    newRoot.rightChild = rotRoot #deal new root right child
    rotRoot.parent = newRoot #deal old root parent
    rotRoot.balanceFactor = rotRoot.balanceFactor - 1 - min(newRoot.balanceFactor, 0)
    newRoot.balanceFactor = newRoot.balanceFactor - 1 + max(rotRoot.balanceFactor, 0)

def rebalance(self,node):
    if node.balanceFactor &lt; 0:
        if node.rightChild.balanceFactor &gt; 0:
            self.rotateRight(node.rightChild)
            self.rotateLeft(node)
        else:
            self.rotateLeft(node)
    elif node.balanceFactor &gt; 0:
        if node.leftChild.balanceFactor &lt; 0:
            self.rotateLeft(node.leftChild)
            self.rotateRight(node)
        else:
            self.rotateRight(node)
</code></pre>

<h1 id="test-code">test code</h1>
<p># test avl tree
print(‘test avl’)
mytree = AVLTree()
mytree[3]=”red”
mytree[4]=”blue”
mytree[6]=”yellow”
mytree[2]=”at”
mytree[5]=’dog’
mytree[1]=’cat’
mytree.levelorder(mytree.root)</p>

<h1 id="test-bst">test bst</h1>
<p>print(‘test bst’)
mytree = BinarySearchTree()
mytree[3]=”red”
mytree[4]=”blue”
mytree[6]=”yellow”
mytree[2]=”at”
mytree[5]=’dog’
mytree[1]=’cat’
mytree.levelorder(mytree.root)</p>

<h1 id="test-avl">test avl</h1>
<p># [4, ‘blue’]
# [2, ‘at’, 4]
# [6, ‘yellow’, 4]
# [1, ‘cat’, 2]
# [3, ‘red’, 2]
# [5, ‘dog’, 6]
# test bst
# [3, ‘red’]
# [2, ‘at’, 3]
# [4, ‘blue’, 3]
# [1, ‘cat’, 2]
# [6, ‘yellow’, 4]
# [5, ‘dog’, 6]</p>

<p>```</p>

<p>对于我给定的测试数据，对应得到的二叉查找树和AVL树如下图所示，二叉查找树明显不平衡，AVL树中所有节点的平衡因子为0或者1，在构造的过程中，共发生了一次左旋和一次右旋。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bst_avl.png" alt="images" /></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - Data Structures]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/08/python-algorithms-datastructures/"/>
    <updated>2014-05-08T10:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/08/python-algorithms-datastructures</id>
    <content type="html"><![CDATA[<p>参考内容：</p>

<p>1.<a href="http://interactivepython.org/courselib/static/pythonds/index.html">Problem Solving with Python</a></p>

<p>Chapter 2 Algorithm Analysis <br />
Chapter 3 Basic Data Structures <br />
Chapter 6 Trees and Tree Algorithms   </p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<h4 id="section">数据结构总结</h4>

<p>1.Python内置数据结构的性能分析</p>

<p>(1)List</p>

<p>List的各个操作的时间复杂度</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/listoptime.png" alt="image" /></p>

<p>同样是执行1000次创建一个包含1-1000的列表，四种方式使用的时间差距很大！使用append比逐次增加要快很多，另外，使用python的列表产生式比append要快，而第四种方式更加快！</p>

<p>```python
def test1():
   l = []
   for i in range(1000):
      l = l + [i]
def test2():
   l = []
   for i in range(1000):
      l.append(i)
def test3():
   l = [i for i in range(1000)]
def test4():
   l = list(range(1000))</p>

<h1 id="import-the-timeit-module---import-timeit">Import the timeit module -&gt; import timeit</h1>
<p># Import the Timer class defined in the module
from timeit import Timer
# If the above line is excluded, you need to replace Timer with
# timeit.Timer when defining a Timer object
t1 = Timer(“test1()”, “from <strong>main</strong> import test1”)
print(“concat “,t1.timeit(number=1000), “milliseconds”)
t2 = Timer(“test2()”, “from <strong>main</strong> import test2”)
print(“append “,t2.timeit(number=1000), “milliseconds”)
t3 = Timer(“test3()”, “from <strong>main</strong> import test3”)
print(“comprehension “,t3.timeit(number=1000), “milliseconds”)
t4 = Timer(“test4()”, “from <strong>main</strong> import test4”)
print(“list range “,t4.timeit(number=1000), “milliseconds”)</p>

<h1 id="concat--17890608310699463-milliseconds">(‘concat ‘, 1.7890608310699463, ‘milliseconds’)</h1>
<p># (‘append ‘, 0.13796091079711914, ‘milliseconds’)
# (‘comprehension ‘, 0.05671119689941406, ‘milliseconds’)
# (‘list range ‘, 0.014147043228149414, ‘milliseconds’)
```</p>

<p><code>timeit</code>模块的解释：</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/timeit.png" alt="image" /></p>

<p>测试pop操作：从结果可以看出，pop最后一个元素的效率远远高于pop第一个元素</p>

<p>```
x = list(range(2000000))
pop_zero = Timer(“x.pop(0)”,”from <strong>main</strong> import x”)
print(“pop_zero “,pop_zero.timeit(number=1000), “milliseconds”)
x = list(range(2000000))
pop_end = Timer(“x.pop()”,”from <strong>main</strong> import x”)
print(“pop_end “,pop_end.timeit(number=1000), “milliseconds”)</p>

<h1 id="popzero--19101738929748535-milliseconds">(‘pop_zero ‘, 1.9101738929748535, ‘milliseconds’)</h1>
<p># (‘pop_end ‘, 0.00023603439331054688, ‘milliseconds’)
```</p>

<p>(2)Dictionary</p>

<p>Dictionary的各个操作的性能</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/dictionary.png" alt="image" /></p>

<p>Dictionary和List的性能比较：list基本上随着其元素的数目呈线性增长，而dictionary一直维持在很短很短的时间内(我的机子测试的结果都是<code>0.001ms</code>)。</p>

<p>```
import timeit
import random</p>

<p>for i in range(10000,1000001,20000):
    t = timeit.Timer(“random.randrange(%d) in x”%i,”from <strong>main</strong> import random,x”)
    x = list(range(i))
    lst_time = t.timeit(number=1000)
    x = {j:None for j in range(i)}
    d_time = t.timeit(number=1000)
    print(“%d,%10.3f,%10.3f” % (i, lst_time, d_time))
```</p>

<p>结果图</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/compare.png" alt="image" /></p>

<p>2.栈：LIFO结构，后进先出</p>

<p>栈能解决的问题很多，比如逆波兰表达式求值，得到一个十进制数的二进制表达，检查括号匹配问题以及图的深度搜索等等，都很简单，可查看参考内容1学习。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/stack.png" alt="image" /></p>

<p>```python
# Completed implementation of a stack ADT
class Stack:
    def <strong>init</strong>(self):
       self.items = []
    def is_empty(self):
       return self.items == []
    def push(self, item):
       self.items.append(item)
    def pop(self):
       return self.items.pop()
    def peek(self):
       return self.items[len(self.items)-1]
    def size(self):
       return len(self.items)</p>

<p>s = Stack()
print(s.is_empty())
s.push(4)
s.push(‘dog’)
print(s.peek())
s.push(True)
print(s.size())
print(s.is_empty())
s.push(8.4)
print(s.pop())
print(s.pop())
print(s.size())
```</p>

<p>3.队列：FIFO结构，先进先出</p>

<p>队列一般用于解决需要优先队列的问题或者进行广度优先搜索的问题，也很简单。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/queue.png" alt="image" /></p>

<p>```python
# Completed implementation of a queue ADT
class Queue:
   def <strong>init</strong>(self):
      self.items = []
   def is_empty(self):
      return self.items == []
   def enqueue(self, item):
      self.items.insert(0,item)
   def dequeue(self):
      return self.items.pop()
   def size(self):
      return len(self.items)</p>

<p>q = Queue()
q.enqueue(‘hello’)
q.enqueue(‘dog’)
print(q.items)
q.enqueue(3)
q.dequeue()
print(q.items)
```</p>

<p>4.双向队列：左右两边都可以插入和删除的队列</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/deque.png" alt="image" /></p>

<p>下面的实现是以右端为front，左端为rear</p>

<p>```python
# Completed implementation of a deque ADT
class Deque:
   def <strong>init</strong>(self):
      self.items = []
   def is_empty(self):
      return self.items == []
   def add_front(self, item):
       self.items.append(item)
   def add_rear(self, item):
      self.items.insert(0,item)
   def remove_front(self):
      return self.items.pop()
   def remove_rear(self):
      return self.items.pop(0)
   def size(self):
      return len(self.items)</p>

<p>dq=Deque();
dq.add_front(‘dog’);
dq.add_rear(‘cat’);
print(dq.items)
dq.remove_front();
dq.add_front(‘pig’);
print(dq.items)
```</p>

<p>5.二叉树：一个节点最多有两个孩子节点的树。如果是从0索引开始存储，那么对应于节点p的孩子节点是2p+1和2p+2两个节点，相反，节点p的父亲节点是(p-1)/2位置上的点</p>

<p>二叉树的应用很多，比如对算术表达式建立一颗二叉树可以清楚看出表达式是如何计算的(详情请见参考内容1)，二叉树的变种可以得到其他的有一定特性的数据结构，例如后面的二叉堆。二叉树的三种遍历方法(前序，中序，后序)同样有很多的应用，比较简单，略过。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bt2.png" alt="image" /></p>

<p>第一种，直接使用list来实现二叉树，可读性差</p>

<p>```python
def binary_tree(r):
    return [r, [], []]
def insert_left(root, new_branch):
    t = root.pop(1)
    if len(t) &gt; 1:
        #new_branch becomes the left node of root, and original left
        #node t becomes left node of new_branch, right node is none
        root.insert(1, [new_branch, t, []])
    else:
        root.insert(1, [new_branch, [], []])
    return root
def insert_right(root, new_branch):
    t = root.pop(2)
    if len(t) &gt; 1:
        root.insert(2, [new_branch, [], t])
    else:
        root.insert(2, [new_branch, [], []])
    return root
def get_root_val(root):
    return root[0]
def set_root_val(root, new_val):
    root[0] = new_val
def get_left_child(root):
    return root[1]
def get_right_child(root):
    return root[2]</p>

<p>r = binary_tree(3)
insert_left(r, 4)
insert_left(r, 5)
insert_right(r, 6)
insert_right(r, 7)
print(r)
l = get_left_child(r)
print(l)
set_root_val(l, 9)
print(r)
insert_left(l, 11)
print(r)
print(get_right_child(get_right_child(r)))
```</p>

<p>第二种，使用类的形式定义二叉树，可读性更好</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/btclass.png" alt="image" /></p>

<p>```
class BinaryTree:
    def <strong>init</strong>(self, root):
        self.key = root
        self.left_child = None
        self.right_child = None
    def insert_left(self, new_node):
        if self.left_child == None:
            self.left_child = BinaryTree(new_node)
        else:
            t = BinaryTree(new_node)
            t.left_child = self.left_child
            self.left_child = t
    def insert_right(self, new_node):
        if self.right_child == None:
            self.right_child = BinaryTree(new_node)
        else:
            t = BinaryTree(new_node)
            t.right_child = self.right_child
            self.right_child = t
    def get_right_child(self):
        return self.right_child
    def get_left_child(self):
        return self.left_child
    def set_root_val(self, obj):
        self.key = obj
    def get_root_val(self):
        return self.key</p>

<p>r = BinaryTree(‘a’)
print(r.get_root_val())
print(r.get_left_child())
r.insert_left(‘b’)
print(r.get_left_child())
print(r.get_left_child().get_root_val())
r.insert_right(‘c’)
print(r.get_right_child())
print(r.get_right_child().get_root_val())
r.get_right_child().set_root_val(‘hello’)
print(r.get_right_child().get_root_val())
```</p>

<p>6.二叉堆：根据堆的性质又可以分为最小堆和最大堆，是一种非常好的优先队列。在最小堆中孩子节点一定大于等于其父亲节点，最大堆反之。二叉堆实际上一棵完全二叉树，并且满足堆的性质。对于插入和查找操作的时间复杂度度都是$O(nlogn)$。</p>

<p>它的插入操作图示：</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/heapinsert.png" alt="image" /></p>

<p>去除根节点的操作图示：</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/heapdel.png" alt="image" /></p>

<p>注意，下面的实现中默认在初始的堆列表中插入了一个元素0，这样做可以保证堆的真实有效的元素个数和current_size值对应，而且最后一个元素的索引就对应了current_size。</p>

<p>此外，从list中建堆的过程需要从最后一个非叶子节点开始到第一个非叶子节点(根节点)进行。这篇文章<a href="http://www.cnblogs.com/Anker/archive/2013/01/23/2873422.html">来自博客园</a>解释了这个问题。建堆的过程如下：[下图摘自原博客，版权归原作者，谢谢]</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/heapbuild.png" alt="image" /></p>

<p>```python
class BinHeap:
    def <strong>init</strong>(self):
        self.heap_list = [0]
        self.current_size = 0
    def perc_up(self, i):
        while i // 2 &gt; 0: # &gt;0 means this node is still available
            if self.heap_list[i] &lt; self.heap_list[i // 2]:
                tmp = self.heap_list[i // 2]
                self.heap_list[i // 2] = self.heap_list[i]
                self.heap_list[i] = tmp
            i = i // 2
    def insert(self, k):
        self.heap_list.append(k)
        self.current_size = self.current_size + 1
        self.perc_up(self.current_size)
    def perc_down(self, i):
        while (i * 2) &lt;= self.current_size:
            mc = self.min_child(i)
            if self.heap_list[i] &gt; self.heap_list[mc]:
                tmp = self.heap_list[i]
                self.heap_list[i] = self.heap_list[mc]
                self.heap_list[mc] = tmp
            i = mc
    def min_child(self, i):
        if i * 2 + 1 &gt; self.current_size:
            return i * 2
        else:
            if self.heap_list[i * 2] &lt; self.heap_list[i * 2 + 1]:
                return i * 2
            else:
                return i * 2 + 1
    def del_min(self):
        ret_val = self.heap_list[1]
        self.heap_list[1] = self.heap_list[self.current_size]
        self.current_size = self.current_size - 1
        self.heap_list.pop()
        self.perc_down(1)
        return ret_val</p>

<pre><code>def build_heap(self, a_list):
    i = len(a_list) // 2
    self.current_size = len(a_list)
    self.heap_list = [0] + a_list[:] #append original list
    while (i &gt; 0):
        #build the heap we only need to deal the first part!
        self.perc_down(i)
        i=i-1
</code></pre>

<p>a_list=[9, 6, 5, 2, 3];
bh=BinHeap();
bh.build_heap(a_list);
print(bh.heap_list)
print(bh.current_size)
bh.insert(10)
bh.insert(7)
print(bh.heap_list)
bh.del_min();
print(bh.heap_list)
print(bh.current_size)
```</p>

<p>关于二叉查找树等内容请见<a href="http://hujiaweibujidao.github.io/blog/2014/05/08/python-algorithms-Trees/">树的总结</a>。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - Sort]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/07/python-algorithms-sort/"/>
    <updated>2014-05-07T22:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/07/python-algorithms-sort</id>
    <content type="html"><![CDATA[<p>参考内容：</p>

<p>1.<a href="http://interactivepython.org/courselib/static/pythonds/index.html">Problem Solving with Python</a></p>

<p>Chapter5: Search and Sorting <a href="http://interactivepython.org/courselib/static/pythonds/SortSearch/sorting.html">online_link</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<h4 id="section">排序总结</h4>

<p>1.冒泡排序(bubble sort)：每个回合都从第一个元素开始和它后面的元素比较，如果比它后面的元素更大的话就交换，一直重复，直到这个元素到了它能到达的位置。注意检测是否已经完成了排序，如果已完成就可以退出了。时间复杂度$O(n^2)$</p>

<p><strong>Python支持对两个数字同时进行交换！<code>a,b = b,a</code>就可以交换a和b的值了。</strong></p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/bubblesort.png" alt="image" /></p>

<p>```python
def short_bubble_sort(a_list):
    exchanges = True
    pass_num = len(a_list) - 1
    while pass_num &gt; 0 and exchanges:
        exchanges = False
        for i in range(pass_num):
            if a_list[i] &gt; a_list[i + 1]:
                exchanges = True
                # temp = a_list[i]
                # a_list[i] = a_list[i + 1]
                # a_list[i + 1] = temp
                a_list[i],a_list[i+1] = a_list[i+1], a_list[i]
        pass_num = pass_num - 1</p>

<p>if <strong>name</strong> == ‘<strong>main</strong>’:
    a_list=[20, 40, 30, 90, 50, 80, 70, 60, 110, 100]
    short_bubble_sort(a_list)
    print(a_list)
```</p>

<p>2.选择排序(selection sort)：每个回合都选择出剩下的元素中最大的那个，选择的方法是首先默认第一元素是最大的，如果后面的元素比它大的话，那就更新剩下的最大的元素值，找到剩下元素中最大的之后将它放入到合适的位置就行了。时间复杂度$O(n^2)$</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/selectionsort.png" alt="image" /></p>

<p>```
def selection_sort(a_list):
    for fill_slot in range(len(a_list) - 1, 0, -1):
        pos_of_max = 0
        for location in range(1, fill_slot + 1):
            if a_list[location] &gt; a_list[pos_of_max]:
                pos_of_max = location
        # temp = a_list[fill_slot]
        # a_list[fill_slot] = a_list[pos_of_max]
        # a_list[pos_of_max] = temp
        a_list[fill_slot],a_list[pos_of_max]=a_list[pos_of_max],a_list[fill_slot]</p>

<p>a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]
selection_sort(a_list)
print(a_list)
```</p>

<p>3.插入排序(insertion sort)：每次假设前面的元素都是已经排好序了的，然后将当前位置的元素插入到原来的序列中，为了尽快地查找合适的插入位置，可以使用二分查找。时间复杂度$O(n^2)$，别误以为二分查找可以降低它的复杂度，因为插入排序还需要移动元素的操作！</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/insertionsort.png" alt="image" /></p>

<p>```python
def insertion_sort(a_list):
    for index in range(1, len(a_list)):
        current_value = a_list[index]
        position = index
        while position &gt; 0 and a_list[position - 1] &gt; current_value:
            a_list[position] = a_list[position - 1]
            position = position - 1
        a_list[position] = current_value</p>

<p>def insertion_sort_binarysearch(a_list):
    for index in range(1, len(a_list)):
        current_value = a_list[index]
        position = index
        low=0
        high=index-1
        while low&lt;=high:
            mid=(low+high)/2
            if a_list[mid]&gt;current_value:
                high=mid-1
            else:
                low=mid+1
        while position &gt; low:
            a_list[position] = a_list[position - 1]
        a_list[position] = current_value</p>

<p>a_list = [54, 26, 93, 15, 77, 31, 44, 55, 20]
insertion_sort(a_list)
print(a_list)
insertion_sort_binarysearch(a_list)
print(a_list)
```</p>

<p>4.合并排序(merge sort)：典型的是二路合并排序，将原始数据集分成两部分(不一定能够均分)，分别对它们进行排序，然后将排序后的子数据集进行合并，这是典型的分治法策略。时间复杂度$O(nlogn)$</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/mergesort.png" alt="image" /></p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/mergesort2.png" alt="image" /></p>

<p>```python
def merge_sort(a_list):
    print(“Splitting “, a_list)
    if len(a_list) &gt; 1:
        mid = len(a_list) // 2
        left_half = a_list[:mid]
        right_half = a_list[mid:]
        merge_sort(left_half)
        merge_sort(right_half)
        i=0;j=0;k=0;
        while i &lt; len(left_half) and j &lt; len(right_half):
            if left_half[i] &lt; right_half[j]:
                a_list[k] = left_half[i]
                i=i+1
            else:
                a_list[k] = right_half[j]
                j=j+1
            k=k+1
        while i &lt; len(left_half):
            a_list[k] = left_half[i]
            i=i+1
            k=k+1
        while j &lt; len(right_half):
            a_list[k] = right_half[j]
            j=j+1
            k=k+1
    print(“Merging “, a_list)</p>

<p>a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]
merge_sort(a_list)
print(a_list)
```</p>

<p>算法导论2-4题利用合并排序可以在$O(nlogn)$的最坏情况下得到包含n个元素的数组的逆序对的数目。[下面使用的是C++来实现的，合并排序的代码格式类似算法导论]</p>

<p>```cpp
#include <iostream>
using namespace std;</iostream></p>

<p>int calculateInversions(int arr[], int p, int r);
int mergeInversions(int arr[], int p, int q, int r);</p>

<p>int main(int argc, const char * argv[])
{
    int arr[] = {2,3,8,6,1};
    int count = calculateInversions(arr, 0, 4);
    cout « “count inversions : “ « count « endl;
    return 0;
}</p>

<p>int calculateInversions(int arr[], int p, int r) {
	int count=0;
	if(p &lt; r) {
		int q = (p + r) / 2;
        count += calculateInversions(arr, p, q);
        count += calculateInversions(arr, q+1, r);
        count += mergeInversions(arr, p, q, r);
	}
	return count;
}</p>

<p>int mergeInversions(int arr[], int p, int q, int r){
    int count=0;
    int n1=q-p+1, n2=r-q;
    int left[n1+1], right[n2+1];
    for (int i=0; i&lt;n1; i++) {
        left[i]=arr[p+i];
    }
    for (int j=0; j&lt;n2; j++) {
        right[j]=arr[q+1+j];
    }
    left[n1]=INT32_MAX;
    right[n2]=INT32_MAX;
    int i=0, j=0;
    for (int k=p; k&lt;=r; k++) {
        if (left[i]&lt;=right[j]) {
            arr[k]=left[i];
            i++;
        }else{
            arr[k]=right[j];
            count += n1-i;
            j++;
        }
    }
    return count;
}
```</p>

<p>5.快速排序(quick sort)：</p>

<p>想法一：如下图所示，它选择第一个元素作为主元，它同样可以按照下面提到的算法导论中将数组分成了4个不同的部分，但是这里其实有更好的解释方法。<strong>首先，它每次都是选择第一个元素都为主元，这个回合就是要确定主元的位置；然后，有两个指针，一个leftmark指向主元的后面一个位置，另一个rightmark指向要排序的数组最后一个元素；接着，两个指针分别向中间移动，leftmark遇到比主元大的元素停止，rightmark遇到比主元小的元素停止，如果此时leftmark&lt;rightmark，也就是说中间还有未处理(未确定与主元大小关系)的元素，那么就交换leftmark和rightmark位置上的元素，然后重复刚才的移动操作，直到rightmark&lt;leftmark；最后，停止移动时候rightmark就是主元要放置的位置，因为它停在一个比主元小的元素的位置上，之后交换主元和rightmark指向的元素即可。完了之后，递归地对主元左右两边的数组进行排序即可。</strong></p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/quicksort.png" alt="image" /></p>

<p>```python
def quick_sort(a_list):
    quick_sort_helper(a_list, 0, len(a_list) - 1)</p>

<p>def quick_sort_helper(a_list, first, last):
    if first &lt; last:
        split_point = partition(a_list, first, last)
        quick_sort_helper(a_list, first, split_point - 1)
        quick_sort_helper(a_list, split_point + 1, last)</p>

<p>def partition(a_list, first, last):
    pivot_value = a_list[first]
    left_mark = first + 1
    right_mark = last
    done = False
    while not done:
        while left_mark &lt;= right_mark and a_list[left_mark] &lt;= pivot_value:
            left_mark = left_mark + 1
        while a_list[right_mark] &gt;= pivot_value and right_mark &gt;= left_mark:
            right_mark = right_mark - 1
        if right_mark &lt; left_mark:
            done = True
        else:
            temp = a_list[left_mark]
            a_list[left_mark] = a_list[right_mark]
            a_list[right_mark] = temp
    temp = a_list[first]
    a_list[first] = a_list[right_mark]
    a_list[right_mark] = temp
    return right_mark</p>

<p>a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]
quick_sort(a_list)
print(a_list)
```</p>

<p>想法二：如下图所示，它选择最后的那个元素作为主元，它的思路是将数组划分成4部分：</p>

<p>第一部分：$p \le k \le i, A[k] \le pivot$</p>

<p>第二部分：$i+1 \le k \le j-1, A[k] \gt pivot$</p>

<p>第三部分：$j \le k \le r-1, A[k]$可以取任何值(因为它们还没有进行处理)。</p>

<p>第四部分：$p \le k \le i, A[k] = pivot$</p>

<p><strong>首先，让i指向要排序的数组的第一个元素的前面，p和j都指向第一个元素；然后，一直移动j直到主元前一个位置，一旦发现一个大于主元的元素就让i指向它的下一个位置，然后交换i和j对应位置上的元素。这样一定是可行的，因为i一直都是指向已发现的小于主元的元素中的最后一个，从i+1开始就大于主元了(或者还未确定/未处理)，而j一直都是指向大于主元的元素中最后一个的后面一个位置，所以i+1和j位置上的元素交换就可以使得j发现的这个小于主元的元素移动到第一部分，而i+1位置上大于主元的元素移动到j的位置上，即第二部分的最后一个位置上。</strong></p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/quicksort_cn.png" alt="image" /></p>

<p>根据算法导论中的伪代码的C++版本实现</p>

<p>```cpp
#include <iostream>
using namespace std;</iostream></p>

<p>// partition, locate the pivot value in properate position
int partition(int a[], int low, int high){
    int key = a[high];//pivot
    int i=low-1, temp;
    for (int j=low; j&lt;high; j++) {
        if (a[j]&lt;key) {
            i++;
            temp = a[j];
            a[j]=a[i];
            a[i]=temp;
        }
    }
    temp = a[high];
    a[high] = a[i+1];
    a[i+1] = temp;//i+1 is the split point
    return i+1;
}</p>

<p>// quick sort
void quicksort(int a[], int low, int high) {
    if (low &lt; high) {
        int p = partition(a,low,high);
        quicksort(a, low, p-1);
        quicksort(a, p+1, high);
    }
}</p>

<p>// print array
void print(int a[],int len){
    for (int i=0; i&lt;len; i++) {
        cout « a[i] « ” ”;
    }
    cout « endl;
}</p>

<p>int main(int argc, const char * argv[])
{
    int a[]={3,5,2,7,9,10,33,28,19,6,8};
    quicksort(a, 0, 10);
    print(a,11);
}
```</p>

<p>由于快排每次都能够确定一个元素在数组中最终的位置，所以可以用快排来解决很多变种问题，例如在线性时间内求中位数或者其他顺序统计量的问题(例如第k大或者第k小的元素)，该部分内容可以参考<a href="http://www.cnblogs.com/Anker/archive/2013/01/25/2877311.html">来自博客园</a></p>

<p>关于快排的性能分析可以参考<a href="http://www.cnblogs.com/Anker/archive/2013/01/24/2875234.html">来自博客园</a>，一般来说划分之后两边越均衡的话快排的性能更好。为了避免最坏的情况出现(原始的数组是已经是有序的)可以使用随机化版本的快排。</p>

<p>另外，为了减少快排的栈深度可以使用尾递归技术，该内容可以参见算法导论习题7-4。</p>

<p>6.希尔排序：类似合并排序和插入排序的结合体，二路合并排序将原来的数组分成左右两部分，希尔排序则将数组按照一定的间隔分成几部分，每部分采用插入排序来排序，有意思的是这样做了之后，元素很多情况下就差不多在它应该呆的位置，所以效率不一定比插入排序差。时间复杂度为$[O(n),O(n^2)]$。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/shellsort.png" alt="image" /></p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/shellsort2.png" alt="image" /></p>

<p>```python
def shell_sort(a_list):
    #how many sublists, also how many elements in a sublist
    sublist_count = len(a_list) // 2
    while sublist_count &gt; 0:
        for start_position in range(sublist_count):
            gap_insertion_sort(a_list, start_position, sublist_count)
        print(“After increments of size”, sublist_count, “The list is”, a_list)
        sublist_count = sublist_count // 2</p>

<p>def gap_insertion_sort(a_list, start, gap):
    #start+gap is the second element in this sublist
    for i in range(start + gap, len(a_list), gap):
        current_value = a_list[i]
        position = i
        while position &gt;= gap and a_list[position - gap] &gt; current_value:
            a_list[position] = a_list[position - gap] #move backward
            position = position - gap
            a_list[position] = current_value</p>

<p>a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20, 88]
shell_sort(a_list)
print(a_list)
```</p>

<p>7.堆排序请参见该系列文章中的<a href="http://hujiaweibujidao.github.io/blog/2014/05/08/python-algorithms-datastructures/">DataStrctures章节中的二叉堆部分的内容</a>。</p>

<p>8.其他线性排序可以参见算法导论第8章或者看下<a href="http://www.cnblogs.com/Anker/archive/2013/01/25/2876397.html">这篇不错的文章</a></p>

<p>其实看个图就明白了，图摘自上面的博客，版权归原作者，谢谢！</p>

<p>计数排序：在数的范围很小时还是不错的，当数的范围很大的时候就不适用了，计数排序一般用于基数排序中。需要注意的是，计数完了之后进行插入时，为了保证排序的稳定性，需要从后往前插入。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/sortcount.png" alt="image" /></p>

<p>基数排序</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/sortradix.png" alt="image" /></p>

<p>桶排序：适用于元素是均匀分布的，在每个桶内采用插入排序。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/sortbucket.png" alt="image" /></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - Search]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/07/python-algorithms-search/"/>
    <updated>2014-05-07T16:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/07/python-algorithms-search</id>
    <content type="html"><![CDATA[<p>参考内容：</p>

<p>1.<a href="http://interactivepython.org/courselib/static/pythonds/index.html">Problem Solving with Python</a>
Chapter5: Search and Sorting <a href="http://interactivepython.org/courselib/static/pythonds/SortSearch/searching.html#searching">online_link</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<h4 id="section">搜索总结</h4>

<p>(1)顺序查找：O(n)</p>

<p>(2)二分查找：O(lgn)</p>

<p>(3)Hash查找：O(1)</p>

<p>概念：hash，hash table，hash function <a href="http://zh.wikipedia.org/wiki/%E5%93%88%E5%B8%8C%E8%A1%A8#.E5.A4.84.E7.90.86.E7.A2.B0.E6.92.9E">哈希表_on_wiki</a></p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/hashbasics.png" alt="image" />  </p>

<p>常用的哈希函数：</p>

<p>1.reminder method：取余数（size=11）</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/reminder.png" alt="image" /></p>

<p>2.folding method</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/folding.png" alt="image" /></p>

<p>3.mid-square method</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/mid-square.png" alt="image" /></p>

<p>4.对于由字符的元素可以尝试使用<code>ord</code>函数来将字符串转换成一个有序的数值序列。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/stringord1.png" alt="image" /></p>

<p>但是，对于通过回文构词法构成的字符串它们得到的值总是一样，为了解决这个问题，可以根据字符的位置添加一个权重。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/stringord2.png" alt="image" /></p>

<p>From wiki</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/hashfun.png" alt="image" />   </p>

<p>使用哈希查找，难免遇到冲突，该如何解决冲突(Collision Resolution)呢？</p>

<p>常用的解决冲突的办法：</p>

<p>1.open address(开放寻址)：线性探测(linear probing)下一个位置，缺点是容易造成聚集现象(cluster)，解决聚集现象的办法是跳跃式地查找下一个空槽。数值的顺序：(54, 26, 93, 17, 77, 31, 44, 55, 20).</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/linearprob.png" alt="image" /></p>

<p>2.quadratic probing(平方探测)：一开始的hash值为h，如果不是空槽，那就尝试h+1，还不是空槽就尝试h+4，依次继续尝试h+9，h+16等等。</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/quadraticprob.png" alt="image" /></p>

<p>3.chain：利用链表链接起来</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/chain.png" alt="image" /></p>

<p>From wiki</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/hashcollision.png" alt="image" />   </p>

<p>分析hash查找的性能：一般使用平均查找长度来衡量，和装载因子有关</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/hashanalysis.png" alt="image" /></p>

<p>From wiki</p>

<p><img src="http://hujiaweibujidao.github.io/images/201405/hashefficiency.png" alt="image" />   </p>

<p>下面的代码包含了顺序查找，二分查找，哈希查找(size=11, plus 1, reminder method)</p>

<p>```python
def sequential_search(a_list, item):
    pos = 0
    found = False
    while pos &lt; len(a_list) and not found:
        if a_list[pos] == item:
            found = True
        else:
            pos = pos+1
    return found</p>

<p>test_list = [1, 2, 32, 8, 17, 19, 42, 13, 0]
print(sequential_search(test_list, 3))
print(sequential_search(test_list, 13))</p>

<p>def binary_search(a_list, item):
    first = 0
    last = len(a_list) - 1
    found = False
    while first &lt;= last and not found:
        midpoint = (first + last) // 2
        if a_list[midpoint] == item:
            found = True
        else:
            if item &lt; a_list[midpoint]:
                last = midpoint - 1
            else:
                first = midpoint + 1
    return found</p>

<p>test_list = [0, 1, 2, 8, 13, 17, 19, 32, 42,]
print(binary_search(test_list, 3))
print(binary_search(test_list, 13))</p>

<p>class HashTable:
    def <strong>init</strong>(self):
        self.size = 11
        self.slots = [None] * self.size
        self.data = [None] * self.size</p>

<pre><code>#put data in slot
def put_data_in_slot(self,key,data,slot):
    if self.slots[slot] == None: # '==None' ? or  'is None' ?
        self.slots[slot] = key
        self.data[slot] = data
        return True
    else:
        if self.slots[slot] == key: # not None
            self.data[slot] = data #replace
            return True
        else:
            return False

def put(self, key, data):
    slot = self.hash_function(key, self.size);
    result = self.put_data_in_slot(key,data,slot);
    while not result:
        slot = self.rehash(slot, self.size);
        result=self.put_data_in_slot(key,data,slot);

#reminder method
def hash_function(self, key, size):
    return key % size

#plus 1
def rehash(self, old_hash, size):
    return (old_hash + 1) % size

def get(self, key):
    start_slot = self.hash_function(key, len(self.slots))
    data = None
    stop = False
    found = False
    position = start_slot
    while self.slots[position] != None and not found and not stop:
        if self.slots[position] == key:
            found = True
            data = self.data[position]
        else:
            position=self.rehash(position, len(self.slots))
            if position == start_slot:
                stop = True
    return data

def __getitem__(self, key):
    return self.get(key)

def __setitem__(self, key, data):
    self.put(key, data)
</code></pre>

<p>if <strong>name</strong> == ‘<strong>main</strong>’:
    table=HashTable();
    table[54]=’cat’;
    table[26]=’dog’;
    table[93]=’lion’;
    table[17]=”tiger”;
    table[77]=”bird”;
    table[44]=”goat”;
    table[55]=”pig”;
    table[20]=”chicken”;
    print table.slots;
    print table.data;</p>

<h1 id="none-26-93-17-none-none-20-54">[77, 44, 55, None, 26, 93, 17, None, None, 20, 54]</h1>
<p># [‘bird’, ‘goat’, ‘pig’, None, ‘dog’, ‘lion’, ‘tiger’, None, None, ‘chicken’, ‘cat’]
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertext Cover Problem]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/04/13/vertext-cover-problem/"/>
    <updated>2014-04-13T23:57:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/04/13/vertext-cover-problem</id>
    <content type="html"><![CDATA[<h4 id="section">1.问题描述</h4>

<p>给定一个N个点M条边的无向图G（点的编号从1至N），问是否存在一个不超过K个点的集合S，使得G中的每条边都至少有一个点在集合S中。</p>

<p>例如，如下图所示的无向图G（报告中算法分析过程中一直使用下面的图G）  </p>

<p>(1)如果选择包含点1,2,6这3个点的集合S不能满足条件，因为边(3,7)两个端点都不在S中。</p>

<p><img src="/images/201404/exp1-3.png" alt="image" /></p>

<p>(2)如果选择包含点1,2,6,7这4个点的集合S虽然满足条件，但是它使用了4个点，其实可以使用更少的点，如下面(3)所示</p>

<p><img src="/images/201404/exp1-2.png" alt="image" /></p>

<p>(3)如果选择包含点1,3,5这3个点的集合S便满足条件，使得G中的每条边都至少有一个点在集合S中。</p>

<p><img src="/images/201404/exp1-1.png" alt="image" /></p>

<h4 id="section-1">2.解题思路</h4>

<p>我的解题思路基于分支定界和贪心两个策略，用一个优先队列维护当前可行的节点，每个节点维护着该节点情况下还可以选择的顶点数目k、需要覆盖的剩余边数e、顶点的状态state、顶点的边数edge等信息，这些节点的排序遵循下面的贪心策略，节点的扩展遵循下面的分支定界策略。总体思路是：</p>

<p>①将原图数据构造成一个解空间树的节点，利用定界策略判断是否有解，如果无解直接退出，如果有可能有解则插入到优先队列中；</p>

<p>②若优先队列不为空，那么便从优先队列中取出第一个可行的节点，进入步骤③，如果优先队列为空则退出；</p>

<p>③判断当前节点是否满足解的条件，如果满足便输出解退出，如果不满足便进入步骤④；</p>

<p>④检查当前节点是否可以扩展，不能扩展的话便进入②继续循环，如果能扩展的话则扩展，然后验证扩展到左右节点是否有解，将有解的扩展节点插入到优先队列中，然后进入②继续循环。</p>

<p>下面分别介绍下分支定界和贪心这两个策略：</p>

<h5 id="section-2">(1)分支定界策略</h5>

<p>首先，界的选择。在一个确定的无向图G中，每个顶点的边即确定了，那么对于该无向图中k个顶点能够覆盖的最多的边数e也就可以确定了！只要对顶点按照边的数目降序排列，然后选择前k个顶点，将它们的边数相加即能得到一个边数上界！因为这k个顶点相互之间可能有边存在也可能没有，所以这是个上界，而且有可能达到。以图G为例，各个顶点的边数统计，并采用降序排列的结果如下：</p>

<!--顶点 | 2 | 3 | 1| 5 | 6| 4| 7 
--| --| --|--|--|--|--|--
边数 | 3 | 3 | 2| 2| 2| 1| 1-->
<!--
顶点 | 边数
----| ---- 
2 | 3 
3 | 3
1 | 2 
5 | 2
6 | 2
4 | 1
7 | 1-->

<p><img src="/images/201404/exp1-f3.png" alt="image" /></p>

<p>假设取k=3个点，那么有Up(e)=(3+3+2)=8 &gt; 7 条边（7为图G的总边数），也就是说，如果从图G中取3个点，要覆盖8条边是有可能的。但是，如果取k=2个点，那么有Up(e)=(3+3)=6 &lt; 7 条边，说明从图G中取2个点，是不可能覆盖G中的全部7条边的！基于这个上界，可以在分支树中扩展出来的节点进行验证，已知它还可以选择的顶点数目以及还需要覆盖的边的条数，加上顶点的状态（下面会分析说明）即可判断当前节点是否存在解！如果不存在即可进行剪枝了。</p>

<p>其次，顶点的状态。该策略中顶点有三种状态，分别为已经选择了的状态S1，不选择的状态S2，可以选择的状态S3。其中，不选择的状态S2对应解空间树中的右节点，不选择该节点，然后设置该节点为不选择状态S2。这点很重要，因为有了这个状态，可以使得上界的判断更为精确，因为只能从剩余顶点集中选择那些状态S3的顶点，状态S1和S2都不行，那么上界便会更小，也就更加精确，从而利于剪枝！</p>

<h5 id="section-3">(2)贪心策略</h5>

<p>贪心的策略是指可行的结点都是按照还需要覆盖的剩余边数的降序排列，即，每次选择的节点都是可行节点中还需要覆盖的边数最小的那个节点，因为它最接近结果了。</p>

<h5 id="section-4">(3)例子分析</h5>

<p>以图G为例，此时e=7（要覆盖的边数），取k=3，图G用邻接矩阵保存为全局数据，计算每个顶点的边数，然后降序排列。</p>

<p>步骤①判断是否可能有解，Up(e)=3+3+2=8&gt;7，可能有解，那么将图G构造成一个解空间树的节点，它包含了还能选择的点数k=3，还需要覆盖的边数e=7，每个顶点的边数以及按边数大小的降序排列（上表），每个顶点的状态（初始时都是可选择的状态S3）。然后，将该节点插入到优先队列中，该优先队列是用最小堆实现的，按照前面的贪心策略对队列中的节点进行降序排列。</p>

<p>步骤②取出了优先队列中的根节点，很显然，还需要覆盖的边数为7，不为0，所以还不满足条件。接下来要检查是否能够进行扩展，从顶点集合中选择状态为可以选择的顶点中边数最多的点，该点存在为顶点2，接着进行扩展，扩展左节点时将还能选择的点数k-1=2，然后计算选择了该点之后删除了几条未覆盖的边，得到还需要覆盖的边数e=4，然后更新所有其他顶点的边数，并重新排序，最后将顶点2的状态设置为已经选择了；扩展右节点时，只要将顶点2的状态设置为不能选择，还能选择的点数k(=3)，还需要覆盖的边数e(=7)保持不变。扩展完了之后，同样判断左右节点是否可能有解，如果有解，将该节点插入到优先队列中。这里左右节点都有解，那么将左右节点都插入到优先队列中，因为左节点还需要覆盖的边数e=4小于右节点的e=7，所以根据贪心策略，左节点在右节点的前面。上面两个步骤的图示如下，其中标明了顶点状态颜色。</p>

<p><img src="/images/201404/exp1-f1.png" alt="image" /></p>

<p>算法然后继续进入步骤②，此时取出的是节点是刚才插入的左节点，很显然，还需要覆盖的边数为4，不为0，所以还不满足条件。接下来要检查是否能够进行扩展，从顶点集合中选择状态为可以选择的顶点中边数最多的点，该点存在为顶点3，接着进行扩展，扩展左节点时将还能选择的点数k-1=1，然后计算选择了该点之后删除了几条未覆盖的边，得到还需要覆盖的边数e=2，然后更新所有其他顶点的边数，并重新排序，最后将顶点3的状态设置为已经选择了；扩展右节点时，只要将顶点3的状态设置为不能选择，还能选择的点数k(=3)，还需要覆盖的边数e(=7)保持不变。扩展完了之后，同样判断左右节点是否可能有解，如果有解，将该节点插入到优先队列中。这里左右节点都不可能有解，那么直接进入步骤②继续循环。上面这一步的图示如下：</p>

<p><img src="/images/201404/exp1-f2.png" alt="image" /></p>

<p>算法按照上面的方式不断进行，最后满足条件的分支的过程是：</p>

<p>①不选择顶点2；②选择顶点3；③选择顶点1；④选择顶点5。</p>

<p>最后得到的满足条件的解是选择顶点1,3,5。</p>

<h4 id="section-5">(4)复杂度分析</h4>

<p>该算法优先队列使用的是最小堆实现的(O(nlgn))，对顶点按照边排序使用的是快速排序算法(O(nlgn))，解空间树的深度最多为顶点数目n，每层都要进行分支定界，所以每层的时间复杂度为O(nlgn)，所以算法总的时间复杂度为O(n^2 lgn)。但是，为了实现分支定界，每个节点保存的信息量较多，空间复杂度较大。(有木有分析错了，我不太会分析复杂度)</p>

<p>OJ系统的结果为：时间 156ms  空间 1.0MB</p>

]]></content>
  </entry>
  
</feed>
