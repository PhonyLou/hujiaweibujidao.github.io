<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: algorithm | Hujiawei Bujidao]]></title>
  <link href="http://hujiaweibujidao.github.io/blog/categories/algorithm/atom.xml" rel="self"/>
  <link href="http://hujiaweibujidao.github.io/"/>
  <updated>2014-07-03T11:00:41+08:00</updated>
  <id>http://hujiaweibujidao.github.io/</id>
  <author>
    <name><![CDATA[hujiawei]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C9 Graphs]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-graphs/"/>
    <updated>2014-07-01T11:30:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-graphs</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(9)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-9-from-a-to-b-with-edsger-and-friendscenter"><center>Chapter 9: From A to B with Edsger and Friends</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<h4 id="section">图的总结</h4>

<p>Todo List</p>

<p>1.邻接矩阵和邻接表</p>

<p>2.DFS和BFS</p>

<p>3.DFS的应用：拓扑排序和有向无环图的强连通分量</p>

<p>4.最短路径：Dijkstra，Bellman-Ford，Floyd-Warshall等</p>

<p>5.最小生成树：Prim，Kruskal</p>

<p>6.网络流：最大流，最小割，二分图等</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C8 Dynamic Programming]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-dynamic-programming/"/>
    <updated>2014-07-01T11:20:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-dynamic-programming</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(8)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-8-tangled-dependencies-and-memoizationcenter"><center>Chapter 8 Tangled Dependencies and Memoization</center></h3>

<blockquote>
  <p>Twice, adv. Once too often.   <br />
  —— Ambrose Bierce, The Devil’s Dictionary</p>
</blockquote>

<p>本节主要结合一些经典的动规问题介绍动态规划的备忘录法和迭代法这两种实现方式，并对这两种方式进行对比</p>

<p>[这篇文章还会更新]</p>

<hr />

<p>大家都知道，动态规划算法一般都有两种实现方式：</p>

<p><strong>1.直接自顶向下实现递归式，并将中间结果保存，这叫备忘录法；</strong></p>

<p><strong>2.按照递归式自底向上地迭代，将结果保存在某个数据结构中求解。</strong></p>

<p>编程有一个原则<code>DRY=Don’t Repeat Yourself</code>，就是说你的代码不要重复来重复去的，这个原则同样可以用于理解动态规划，动态规划除了满足最优子结构，它还存在子问题重叠的性质，我们不能重复地去解决这些子问题，所以我们将子问题的解保存起来，类似缓存机制，之后遇到这个子问题时直接取出子问题的解。</p>

<p>举个简单的例子，斐波那契数列中的元素的计算，很简单，我们写下如下的代码：</p>

<p><code>python
def fib(i):
    if i&lt;2: return 1
    return fib(i-1)+fib(i-2)
</code></p>

<p>好，来测试下，运行<code>fib(10)</code>得到结果69，不错，速度也还行，换个大的数字，试试100，这时你会发现，这个程序执行不出结果了，为什么？递归太深了！要计算的子问题太多了！</p>

<p>所以，我们需要改进下，我们保存每次计算出来的子问题的解，用什么保存呢？用Python中的dict！那怎么实现保存子问题的解呢？用Python中的装饰器！</p>

<p>如果不是很了解Python的装饰器，可以快速看下<a href="http://hujiaweibujidao.github.io/blog/2014/05/10/python-tips1/">这篇总结中关于装饰器的解释：Python Basics</a></p>

<p>修改刚才的程序，得到如下代码，定义一个函数<code>memo</code>返回我们需要的装饰器，这里用<code>cache</code>保存子问题的解，key是方法的参数，也就是数字<code>n</code>，值就是<code>fib(n)</code>返回的解。</p>

<p>```
from functools import wraps</p>

<p>def memo(func):
    cache={}
    @wraps(func)
    def wrap(<em>args):
        if args not in cache:
            cache[args]=func(</em>args)
        return cache[args]
    return wrap</p>

<p>@memo
def fib(i):
    if i&lt;2: return 1
    return fib(i-1)+fib(i-2)
```
重新运行下<code>fib(100)</code>，你会发现这次很快就得到了结果<code>573147844013817084101</code>，这就是动态规划的威力，上面使用的是第一种带备忘录的递归实现方式。</p>

<p><strong>带备忘录的递归方式的优点就是易于理解，易于实现，代码简洁干净，运行速度也不错，直接从需要求解的问题出发，而且只计算需要求解的子问题，没有多余的计算。但是，它也有自己的缺点，因为是递归形式，所以有限的栈深度是它的硬伤，有些问题难免会出现栈溢出了。</strong></p>

<p>于是，迭代版本的实现方式就诞生了！</p>

<p><strong>迭代实现方式有2个好处：1.运行速度快，因为没有用栈去实现，也避免了栈溢出的情况；2.迭代实现的话可以不使用dict来进行缓存，而是使用其他的特殊cache结构，例如多维数组等更为高效的数据结构。</strong></p>

<p>那怎么把递归版本转变成迭代版本呢？</p>

<p><strong>这就是递归实现和迭代实现的重要区别：递归实现不需要去考虑计算顺序，只要给出问题，然后自顶向下去解就行；而迭代实现需要考虑计算顺序，并且顺序很重要，算法在运行的过程中要保证当前要计算的问题中的子问题的解已经是求解好了的。</strong></p>

<p>斐波那契数列的迭代版本很简单，就是按顺序来计算就行了，不解释，关键是你可以看到我们就用了3个简单变量就求解出来了，没有使用任何高级的数据结构，节省了大量的空间。</p>

<p><code>python
def fib_iter(n):
    if n&lt;2: return 1
    a,b=1,1
    while n&gt;=2:
        c=a+b
        a=b
        b=c
        n=n-1
    return c
</code></p>

<p>斐波那契数列的变种经常出现在上楼梯的走法问题中，每次只能走一个台阶或者两个台阶，广义上思考的话，<strong>动态规划也就是一个连续决策问题，到底当前这一步是选择它(走一步)还是不选择它(走两步)呢?</strong></p>

<p>其他问题也可以很快地变相思考发现它们其实是一样的，例如求二项式系数<code>C(n,k)</code>，杨辉三角(求从源点到目标点有多少种走法)等等问题。</p>

<p>二项式系数<code>C(n,k)</code>表示从n个中选k个，假设我们现在n个中的第1个，考虑是否选择它。如果选择它的话，那么我们还需要从剩下的n-1个中选k-1个，即<code>C(n-1,k-1)</code>；如果不选择它的话，我们需要从剩下的n-1中选k个，即<code>C(n-1,k)</code>。所以，<code>C(n,k)=C(n-1,k-1)+C(n-1,k)</code>。</p>

<p>结合前面的装饰器，我们很快便可以实现求二项式系数的递归实现代码，其中的<code>memo</code>函数完全没变，只是在函数<code>cnk</code>前面添加了<code>@memo</code>而已，就这么简单！</p>

<p>```
from functools import wraps</p>

<p>def memo(func):
    cache={}
    @wraps(func)
    def wrap(<em>args):
        if args not in cache:
            cache[args]=func(</em>args)
        return cache[args]
    return wrap</p>

<p>@memo
def cnk(n,k):
    if k==0: return 1 #the order of <code>if</code> should not change!!!
    if n==0: return 0
    return cnk(n-1,k)+cnk(n-1,k-1)
```</p>

<p>它的迭代版本也比较简单，这里使用了<code>defaultdict</code>，略高级的数据结构，和dict不同的是，当查找的key不存在对应的value时，会返回一个默认的值，这个很有用，下面的代码可以看到。</p>

<p>如果不了解<code>defaultdict</code>的话可以看下<a href="http://blog.jobbole.com/65218/">这篇文章：Python中的高级数据结构</a></p>

<p>```
from collections import defaultdict</p>

<p>n,k=10,7
C=defaultdict(int)
for row in range(n+1):
    C[row,0]=1
    for col in range(1,k+1):
        C[row,col]=C[row-1,col-1]+C[row-1,col]</p>

<p>print(C[n,k]) #120
```</p>

<p>杨辉三角大家都熟悉，在国外这个叫<code>Pascal Triangle</code>，它和二项式系数特别相似，看下图，除了两边的数字之外，里面的任何一个数字都是由它上面相邻的两个元素相加得到，想想<code>C(n,k)=C(n-1,k-1)+C(n-1,k)</code>不也就是这个含义吗?</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/sanjiao.png" alt="image" /></p>

<p>所以说，顺序对于迭代版本的动态规划实现很重要，下面举个实例，用动态规划解决有向无环图的单源最短路径问题。假设有如下图所示的图，当然，我们看到的是这个有向无环图经过了拓扑排序之后的结果，从a到f的最短路径用灰色标明了。</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/dag_sp.png" alt="image" /></p>

<p>好，怎么实现呢? </p>

<p><strong>我们有两种思考方式：</strong></p>

<p><strong>1.”去哪里?”：我们顺向思维，首先假设从a点出发到所有其他点的距离都是无穷大，然后，按照拓扑排序的顺序，从a点出发，接着更新a点能够到达的其他的点的距离，那么就是b点和f点，b点的距离变成2，f点的距离变成9。因为这个有向无环图是经过了拓扑排序的，所以按照拓扑顺序访问一遍所有的点(到了目标点就可以停止了)就能够得到a点到所有已访问到的点的最短距离，也就是说，当到达哪个点的时候，我们就找到了从a点到该点的最短距离，拓扑排序保证了后面的点不会指向前面的点，所以访问到后面的点时不可能再更新它前面的点的最短距离！这种思维方式的代码实现就是迭代版本。</strong></p>

<p><strong>这里涉及到了拓扑排序，我的博客中还没有讲解，所以下面的代码已经将输入的点进行了拓扑排序，待我更新了图算法那篇文章再来更新这里的代码，谅解。</strong></p>

<p>```
def topsort(W):
    return W</p>

<p>def dag_sp(W, s, t):
    d = {u:float(‘inf’) for u in W} #
    d[s] = 0
    for u in topsort(W):
        if u == t: break
        for v in W[u]:
            d[v] = min(d[v], d[u] + W[u][v])
    return d[t]</p>

<h1 id="section">邻接表</h1>
<p>W={0:{1:2,5:9},1:{2:1,3:2,5:6},2:{3:7},3:{4:2,5:3},4:{5:4},5:{}}
s,t=0,5
print(dag_sp(W,s,t)) #7
```</p>

<p>用图来表示计算过程就是下面所示：</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/dag_sp_iter.png" alt="image" /></p>

<p><strong>2.”从哪里来?”：我们逆向思维，目标是要到f，那从a点经过哪个点到f点会近些呢?只能是求解从a点出发能够到达的那些点哪个距离f点更近，这里a点能够到达b点和f点，f点到f点距离是0，但是a到f点的距离是9，可能不是最近的路，所以还要看b点到f点有多近，看b点到f点有多近就是求解从b点出发能够到达的那些点哪个距离f点更近，所以又绕回来了，也就是递归下去，直到我们能够回答从a点经过哪个点到f点会更近。这种思维方式的代码实现就是递归版本。</strong></p>

<p>这种情况下，不需要输入是经过了拓扑排序的，所以你可以任意修改输入<code>W</code>中节点的顺序，结果都是一样的，而上面采用迭代实现方式必须要是拓扑排序了的，从中你就可以看出迭代版本和递归版本的区别了。</p>

<p>```
from functools import wraps
def memo(func):
    cache={}
    @wraps(func)
    def wrap(<em>args):
        if args not in cache:
            cache[args]=func(</em>args)
            # print(‘cache {0} = {1}’.format(args[0],cache[args]))
        return cache[args]
    return wrap</p>

<p>def rec_dag_sp(W, s, t):
    @memo
    def d(u):
        if u == t: return 0
        return min(W[u][v]+d(v) for v in W[u])
    return d(s)</p>

<h1 id="section-1">邻接表</h1>
<p>W={0:{1:2,5:9},1:{2:1,3:2,5:6},2:{3:7},3:{4:2,5:3},4:{5:4},5:{}}
s,t=0,5
print(rec_dag_sp(W,s,t)) #7
```</p>

<p>用图来表示计算过程就是下面所示：</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/dag_sp_rec.png" alt="image" /></p>

<p>下面是参考内容1对DAG求单源最短路径的动态规划问题的总结，比较难理解，不知道我自己理解得对不对，可以忽视注释，:-)</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/dp_summary.png" alt="image" /></p>

<p>好，我们差不多搞清楚了动态规划的本质以及两种实现方式的优缺点，下面我们来实践下，举最常用的例子：<a href="http://hujiaweibujidao.github.io/blog/2014/05/18/matrix-chain/">矩阵链乘问题，内容较多，所以请点击链接过去阅读完了之后回来看总结</a>！</p>

<p>OK，希望我把动态规划讲清楚了，总结下：<strong>动态规划其实就是一个连续决策的过程，每次决策我们可能有多种选择(二项式系数和0-1背包问题中我们只有两个选择，DAG图的单源最短路径中我们的选择要看点的出边或者入边，矩阵链乘问题中就是矩阵链可以分开的位置总数…)，我们每次选择最好的那个作为我们的决策。所以，动态规划的时间复杂度其实和这两者有关，也就是子问题的个数以及子问题的选择个数，一般情况下动态规划算法的时间复杂度就是两者的乘积。动态规划有两种实现方式：一种是带备忘录的递归形式，这种方式直接从原问题出发，遇到子问题就去求解子问题并存储子问题的解，下次遇到的时候直接取出来，问题求解的过程看起来就像是先自顶向下地展开问题，然后自下而上的进行决策；另一个实现方式是迭代方式，这种方式需要考虑如何给定一个子问题的求解方式，使得后面求解规模较大的问题是需要求解的子问题都已经求解好了，它的缺点就是可能有些子问题不要算但是它还是算了，而递归实现方式只会计算它需要求解的子问题。</strong></p>

<hr />

<p>练习：来试试写写最长公共子序列吧，<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/longest-common-subsequence/">这篇文章中给出了Python版本的5种实现方式</a>哟！</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C7 Greedy]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-greedy/"/>
    <updated>2014-07-01T11:10:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-greedy</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(7)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-7-greed-is-good-prove-itcenter"><center>Chapter 7: Greed is good? Prove it!</center></h3>

<p>[编写中]</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C6 Divide and Combine and Conquer]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-divide-and-combine-and-conquer/"/>
    <updated>2014-07-01T11:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-divide-and-combine-and-conquer</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(6)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-6-divide-and-combine-and-conquercenter"><center>Chapter 6: Divide and Combine and Conquer</center></h3>

<p>[编写中]</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C5 Traversal]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-traversal/"/>
    <updated>2014-07-01T10:50:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-traversal</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(5)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-5-traversalcenter"><center>Chapter 5: Traversal</center></h3>

<blockquote>
  <p>You are in a narrow hallway. This continues for several metres and ends in a doorway. Halfway along the passage you can see an archway where some steps lead downwards. Will you go forwards to the door (turn to 5), or creep down the steps (turn to 344)?    <br />
  ——Steve Jackson, Citadel of Chaos</p>
</blockquote>

<p>本节主要介绍图的遍历算法BFS和DFS，以及DFS衍生出的寻找图的(强)连通分量的算法</p>

<p>Traversal就是遍历，主要是对图的遍历，也就是遍历图中的每个节点。对一个节点的遍历有两个阶段，首先是发现(discover)，然后是访问(visit)。遍历的重要性自然不必说，图中有几个算法和遍历没有关系？！</p>

<p>[算法导论对于发现和访问区别的非常明显，对图的算法讲解地特别好，在遍历节点的时候给节点标注它的发现节点时间d[v]和结束访问时间f[v]，然后由这些时间的一些规律得到了不少实用的定理，感兴趣不妨阅读下]</p>

<p>图的连通分量是图的一个最大子图，在这个子图中任何两个节点之间都是相互可达的。我们本节的重点就是想想怎么找到一个图的连通分量呢？</p>

<p>一个很明显的想法是，我们从一个顶点出发，沿着边一直走，慢慢地扩大子图，直到子图不能再扩大了停止，我们就得到了一个连通分量对吧，我们怎么确定我们真的是找到了一个完整的连通分量呢？可以看下作者给出的解释，类似上节的Induction，我们思考从 i-1 到 i 的过程，只要我们保证增加了这个节点后子图仍然是连通的就对了。</p>

<p>Let’s look at the following related problem. Show that you can order the nodes in a connected graph, V1, V2, … Vn, so that for any i = 1…n, the subgraph over V1, … , Vi is connected. If we can show this and we can figure out how to do the ordering, we can go through all the nodes in a connected component and know when they’re all used up.</p>

<p>How do we do this? Thinking inductively, we need to get from i -1 to i. We know that the subgraph over the i -1 first nodes is connected. What next? Well, because there are paths between any pair of nodes, consider a node u in the first i -1 nodes and a node v in the remainder. On the path from u to v, consider the last node that is in the component we’ve built so far, as well as the first node outside it. Let’s call them x and y. Clearly there must be an edge between them, so adding y to the nodes of our growing component keeps it connected, and we’ve shown what we set out to show.</p>

<p>经过上面的一番思考，我们就知道了如何找连通分量：从一个顶点开始，沿着它的边找到其他的节点(或者说站在这个节点上看，看能够发现哪些节点)，然后就是不断地向已有的连通分量中添加节点，使得连通分量内部依然满足连通性质。如果我们按照上面的思路一直做下去，我们就得到了一棵树，一棵遍历树，它也是我们遍历的分量的一棵生成树。这个算法的具体实现时，我们要记录“边缘节点”，也就是那些和已得到的连通分量中的节点相连的节点，这就像是一个待办事项(to-do list)一样，而前面加入的节点就是标记为已完成的(checked off)。</p>

<p>这里作者举了一个很有意思的例子，一个角色扮演的游戏，如下图所示，我们可以将房间看作是节点，将房间的门看作是节点之间的边，走过的轨迹就是遍历树。这么看的话，房间就分成了三种：(1)我们已经经过的房间；(2)我们已经经过的房间附近的房间，也就是马上可以进入的房间；(3)“黑屋”，我们甚至都不知道它们是否存在，存在的话也不知道在哪里。</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/dungeon.png" alt="image" /></p>

<p>根据上面的分析可以写出下面的遍历函数<code>walk</code>，其中参数<code>S</code>暂时没有用，它在后面求强连通分量时需要，表示的是一个“禁区”(forbidden zone)，也就是不要去访问这些节点。</p>

<p>注意下面的<code>difference</code>函数的使用，参数可以是多个，也就是说返回的集合中的元素在参数中都没有存在，此外，参数也不一定是set，也可以是dict或者list，只要是可迭代的(iterables)即可。</p>

<p><code>python
# Walking Through a Connected Component of a Graph Represented Using Adjacency Sets
def walk(G, s, S=set()):                        # Walk the graph from node s
    P, Q = dict(), set()                        # Predecessors + "to do" queue
    P[s] = None                                 # s has no predecessor
    Q.add(s)                                    # We plan on starting with s
    while Q:                                    # Still nodes to visit
        u = Q.pop()                             # Pick one, arbitrarily
        for v in G[u].difference(P, S):         # New nodes?
            Q.add(v)                            # We plan to visit them!
            P[v] = u                            # Remember where we came from
    return P                                    # The traversal tree
</code></p>

<p>我们可以用下面代码来测试下，得到的结果没有问题</p>

<p>```
def some_graph2():
    a, b, c, d, e, f, g, h = range(8)
    N = [
        {b, c, d, e, f},    # a
        {c, e},             # b
        {d},                # c
        {e},                # d
        {f},                # e
        {c, g, h},          # f
        {f, h},             # g
        {f, g}              # h
    ]
    return N</p>

<p>G = some_graph2()
print list(walk(G,0)) #[0, 1, 2, 3, 4, 5, 6, 7]
```</p>

<p>上面的<code>walk</code>函数只适用于无向图，而且只能找到一个从参数<code>s</code>出发的连通分量，要想得到全部的连通分量需要修改下</p>

<p><code>
def components(G):                              # The connected components
    comp = []
    seen = set()                                # Nodes we've already seen
    for u in G:                                 # Try every starting point
        if u in seen: continue                  # Seen? Ignore it
        C = walk(G, u)                          # Traverse component
        seen.update(C)                          # Add keys of C to seen
        comp.append(C)                          # Collect the components
    return comp
</code></p>

<p>用下面的代码来测试下，得到的结果没有问题</p>

<p>```
G = {
    0: set([1, 2]),
    1: set([0, 2]),
    2: set([0, 1]),
    3: set([4, 5]),
    4: set([3, 5]),
    5: set([3, 4])
    }</p>

<p>print [list(sorted(C)) for C in components(G)]  #[[0, 1, 2], [3, 4, 5]]
```</p>

<p>至此我们就完成了一个时间复杂度为$\Theta(E+V)$的求无向图的连通分量的算法，因为每条边和每个顶点都要访问一次。[这个时间复杂度会经常看到，例如拓扑排序，强连通分量都是它]</p>

<p>[中间部分作者介绍了欧拉回路和哈密顿回路：前者是经过图中的所有边一次，然后回到起点；后者是经过图中的所有顶点一次，然后回到起点。网上资料甚多，感兴趣自行了解]</p>

<p>下面我们看下迷宫问题，如下图所示，原始问题是一个人在公园中走路，结果走不出来了，即使是按照“左手准则”(也就是但凡遇到交叉口一直向左转)走下去，如果走着走着回到了原来的起点，那么就会陷入无限的循环中！有意思的是，左边的迷宫可以通过“左手准则”转换成右边的图
[<strong>注：具体的转换方式我还未明白</strong>]</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/maze.png" alt="image" /></p>

<p>[编写中]</p>

]]></content>
  </entry>
  
</feed>
