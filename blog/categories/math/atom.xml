<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: math | Hujiawei Bujidao]]></title>
  <link href="http://hujiaweibujidao.github.io/blog/categories/math/atom.xml" rel="self"/>
  <link href="http://hujiaweibujidao.github.io/"/>
  <updated>2014-04-24T12:09:41+08:00</updated>
  <id>http://hujiaweibujidao.github.io/</id>
  <author>
    <name><![CDATA[hujiawei]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Calculus Summary]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/04/24/calculus-summary/"/>
    <updated>2014-04-24T08:40:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/04/24/calculus-summary</id>
    <content type="html"><![CDATA[<script type="text/javascript" src="https://stackedit.io/libs/MathJax/MathJax.js?config=TeX-AMS_HTML"></script>


<h2><center>微积分总结</center></h2>

<p>[TOC]</p>

<h3><center>第零部分 碎碎念</center></h3>

<p>到了研究生阶段才意识到本科的数学原来作用这么大，不论是在数据挖掘，还是机器学习，亦或是模式识别，数学都是基础中的基础。于是乎，我在逸夫图书馆泡了几天看了些微积分、线代和数理统计的书籍，写下三份总结，记录下重要的知识，以备后忘。本人才疏学浅，若有错误之处还请指出，让我“增长”，若有不足也请指出，使我“完备”，谢谢！:&ndash;)</p>

<p><strong>[注：这些总结不会详细地讲解所有概念，只是挑选一些我个人感觉比较有用的知识点进行总结，很多时候可能只是列举知识点，并无解释，忘记了的可以自行Wiki或者翻书，另外，为了节省写作时间，我剪切粘贴了很多图片&hellip;嗯，就是这样&hellip;]</strong></p>

<p>参考书籍：</p>

<p>1.<a href="http://book.douban.com/subject/2112359/">同济大学 高等数学 高等教育出版社</a></p>

<p>2.<a href="http://product.dangdang.com/23311529.html">高等数学 中国环境出版社</a></p>

<h3><center>第一部分 函数与极限 </center></h3>

<h4>第一节 函数</h4>

<p>集合、区间与邻域，函数的概念与性质，反函数与复合函数，初等函数</p>

<p>关于<a href="http://zh.wikipedia.org/wiki/%E5%88%9D%E7%AD%89%E5%87%BD%E6%95%B0">初等函数 on wiki</a>，初等函数在其定义域内都是连续的。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/elementalfuns.png" title="elementalfuns.png" alt="image" /></p>

<p>关于指数函数：
对于相等间隔的自变量x的取值，指数函数对应值的比例为常数。由指数运算法则可知，对任意的x，只要给定$x<em>{0}>0$，则$a^{x+x</em>{0}}/a^{x}=a^{x_{0}}$恒成立。此性质可以作为判断两个变量之间的关系是否为指数函数关系的主要依据。此外，这个性质导出了数理统计中的指数分布。</p>

<h4>第二节 函数的极限</h4>

<p>数列极限及性质，函数极限及性质，无穷小与无穷大，极限运算法则，极限存在准则和两个重要极限，无穷小的比较</p>

<p>关于收敛数列(极限存在)有两个性质：唯一性和有界性</p>

<p>关于函数极限，注意，$x \to x{0}$的极限是否存在与函数在$x_{0}$是否有定义无关。<a href="http://hujiaweibujidao.github.io/images/math/fun_limit.png" title="fun_limit.png">函数极限的定义</a></p>

<!--![image](http://hujiaweibujidao.github.io/images/math/elementalfuns.png)-->


<p>函数极限的几何意义是，当x在领域$(x<em>{0}&ndash;\delta,x</em>{0}+\delta)$内时，函数值y落在下图中$(A-\varepsilon,A+\varepsilon)$内。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/funlimit_meaning.png" title="funlimit_meaning.png" alt="function limit meaning" /></p>

<p>关于无穷小和无穷大：无穷小并不是指负无穷，而是函数在$x \to x{0}$时的极限为0，无穷小与有解变量的乘积还是无穷小，但是这个性质放在无穷大上面就不成立！例如，$\lim<em>{x \to +\infty} \frac{sinx}{x} = 0$是无穷小，但是$\lim</em>{x \to +\infty} xcosx$不是无穷小，它不符合无穷小的定义，<a href="http://www.guokr.com/post/469944/">关于这个问题的讨论</a>。</p>

<p>两个重要的极限：$\lim<em>{x \to 0} \frac{sinx}{x} = 1$ 和 $\lim</em>{x \to +\infty} (1+\frac{1}{x})^{x} = e$</p>

<p>关于极限$\lim_{x \to 0} \frac{sinx}{x} = 1$可用下图来解释，圆的边长是1，$BC=sinx, AD=tanx, \hat{AB}=x$，在$x \to 0$时，三者近似相等。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/sinxoverx.png" title="sinxoverx.png" alt="sinx over x" /></p>

<p>关于极限$\lim<em>{x \to \infty} (1+\frac{1}{x})^{x} = e$，注意，不论是$\lim</em>{x \to +\infty}$还是$\lim_{x \to &ndash;\infty}$都成立，它道出了自然对数$e$到底是什么！当然还有其他的方式表示出$e$，比如级数的方式，我认为$e$是数学界最美丽的符号！$e \approx 2.71828$</p>

<h4>第三节 函数的连续性与间断点</h4>

<p>函数的连续性，函数的间断点</p>

<p>函数的间断点分为两类：第一类是函数在$x=x_{0}$处间断，但是左右极限都存在，如果左右极限相等的话该间断点称为可去间断点，如果不相等称为跳跃间断点；其他情况下的间断点都属于第二类间断点。</p>

<h4>第四节 初等函数的连续性</h4>

<p>连续函数四则运算的连续性，反函数与复合函数的连续性，初等函数的连续性</p>

<h4>第五节 闭区间上连续函数的性质</h4>

<p>最大值和最小值定理，介值定理与零点定理</p>

<p>最大值和最小值定理就是说在闭区间上的连续函数f(x)一定是有上下界的；</p>

<p>介值定理就是说在闭区间上的连续函数f(x)，如果左右端点的取值不同，例如$f(a)=A,f(b)=B$，那么区间中肯定有一点的函数值能够取到$[A,B]$之间的任何一个值！</p>

<p>零点定理就是说在闭区间上的连续函数f(x)，如果左右端点的取值异号，例如$f(a)=A>0,f(b)=B&lt;0$，那么区间中肯定有一点的函数值为0！</p>

<h3><center>第二部分 导数与微分</center></h3>

<h4>第一节 导数概念</h4>

<p>引例，导数的定义，导数的几何意义，可导与连续的关系</p>

<p>导数的几何意义就是曲线在某点的切线的斜率，反应了变化的快慢，理解这个很重要，以及后面的偏导数的理解，它们最后都应用对一些算法的理解中，例如梯度下降算法，其实就是利用这个几何意义，让要优化的函数尽快地逼近局部最优解。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/deviration_meaning.png" title="deviration_meaning.png" alt="deviration_meaning.png" /></p>

<h4>第二节 函数的求导法则</h4>

<p>函数的和、差、积、商的求导法则，反函数的求导法则，复合函数的求导法则，基本求导法则与导数公式</p>

<p>关于反函数的求导法则：$\frac{dy}{dx}=\frac{1}{\frac{dx}{dy}}$</p>

<p>关于复合函数的求导法则：$\frac{dy}{dx}=\frac{dy}{du} \cdot \frac{du}{dx}$</p>

<p>关于基本初等函数求导法则</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/deviration.png" alt="image" /></p>

<h4>第三节 高阶导数</h4>

<p>二阶及二阶以上的导数称为高阶导数</p>

<h4>第四节 隐函数及其参数方程所确定的函数的导数</h4>

<p>隐函数的导数，由参数方程所确定的函数的导数</p>

<p>如果方程$F(x,y)=0$确定了$y$是$x$的函数，那么这样的函数就叫做隐函数。一般它的求导分为两种方法：(1)如果能够解出$y=f(x)$关系式的话，就先解出然后求导；(2)如果不能解出，那么就利用复合函数求导方式进行求导。</p>

<h4>第五节 函数的微分</h4>

<p>微分的定义，微分的几何意义，基本微分公式与微分法则，微分形式的不变性，微分的应用</p>

<p>先看看微分是怎么引入的？</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/weifen.png" alt="image" /></p>

<p>就是说，在实际应用中，常常需要知道当自变量x有细微变化的时候，函数y的变化量$\vartriangle y$是多少？为了方便计算，需要将增量表达式线性化处理，从而计算出$\vartriangle y$的近似值。如上面所示，我们只需要用$A \vartriangle x$来近似代替$\vartriangle y$。</p>

<p>微分的几何意义，这其实是数学中常用的非线性函数的局部线性化，这里是利用曲线的切线段来近似代替曲线段。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/weifen_meaning.png" alt="image" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Numerical Methods using Matlab]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/04/23/numerical-methods-using-matlab/"/>
    <updated>2014-04-23T22:13:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/04/23/numerical-methods-using-matlab</id>
    <content type="html"><![CDATA[<p>一本关于数值算法与应用的总结小书</p>

<p>目前写了四个章节：[点击章节标题可以直接查看并下载 (^o^)/~]</p>

<ul>
<li><a href="/files/nm-chapter1.pdf">第一章 线性方程组求解</a></li>
</ul>


<p>内容包括：高斯消去法，LU分解，Cholesky分解，矩阵的逆矩阵求解</p>

<ul>
<li><a href="/files/nm-chapter2.pdf">第二章 非线性方程求解</a></li>
</ul>


<p>内容包括：二分法，牛顿法，割线法，IQI法，Zeroin算法</p>

<ul>
<li><a href="/files/nm-chapter3.pdf">第三章 矩阵特征值和奇异值求解</a></li>
</ul>


<p>内容包括：基本幂法，逆幂法和移位幂法，QR分解，Householder变换，实用QR分解技术，奇异值分解SVD</p>

<ul>
<li><a href="/files/nm-chapter4.pdf">第四章 曲线拟合和多项式插值</a></li>
</ul>


<p>内容包括：曲线拟合，拉格朗日插值多项式，牛顿插值多项式，分段线性插值，保形分段三次插值，三次样条插值</p>

<p><img src="/images/201311/nm-cover.png" width="600" height="600" title="" >
<img src="/images/201311/nm-chapter.png" width="600" height="600" title="" >
<img src="/images/201311/nm-math.png" width="600" height="600" title="" >
<img src="/images/201311/nm-code.png" width="600" height="600" title="" ></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[probability and statistics summary]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/04/22/probability-and-statistics-summary/"/>
    <updated>2014-04-22T00:06:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/04/22/probability-and-statistics-summary</id>
    <content type="html"><![CDATA[<h3><center>概率与数理统计总结</center></h3>

<hr />

<p>[TOC]</p>

<h4><center><strong>第零部分 碎碎念</strong></center></h4>

<p>本文是对概率和数理统计中的重要内容的一个小总结，不会侧重很多众所周知的细节，所以有啥疑问还是需要Google或者Wikipedia。关于本文中出现的术语参照参考书籍中的定义，部分可能与大学教材中不同，请自行对应起来理解。小弟才疏学浅，若有错误请留言，欢迎指正。</p>

<p>主要参考书籍：</p>

<p>1.<a href="http://book.douban.com/subject/2985995/">《爱上统计学》</a></p>

<p>2.<a href="http://book.douban.com/subject/7056708/">《深入浅出统计学》</a></p>

<p>3.<a href="http://book.douban.com/subject/24381562/">《统计思维：程序员数学之概率统计》</a></p>

<h4><center><strong>第一部分 概率</strong></center></h4>

<p>1.事件：对立事件(complementary event)，互斥事件(exclusive event)，相交事件(intersecting event)，相关事件(dependent event)，独立事件(independent event)，可以使用韦恩图(Venn Diagram)方便分析事件之间的关系。</p>

<p>如果事件A和B会相互影响，那么它们是相关事件，否则是独立事件。
事件A和B独立：$P(A|B)=P(A) \quad P(A \cap B)=P(A)P(B)$</p>

<p>2.概率：条件概率(Conditional Probability)，全概率(Total Probability)，贝叶斯定理(Bayes' Theorem)</p>

<p>条件概率：$P(A|B)=\frac{P(A \cap B)}{P(B)}$</p>

<p>全概率：$P(B)=P(B|A)P(A)+P(B|A')P(A')$</p>

<p>贝叶斯定理(将条件概率和全概率整合到一起)：$P(A|B)=\frac{P(A \cap B)}{P(B|A)P(A)+P(B|A')P(A')}$</p>

<p>3.期望(Expectation)与方差(Variance)</p>

<p>$E(x)=\Sigma xP(X=x) \quad Var(x)=E(x-\mu)^{2}=\Sigma (x-\mu)<sup>2P</sup>(X=x)=E(x^{2})&ndash;(E(x))^{2}$</p>

<p>线性变换之后的期望与方差：</p>

<p>$E(ax+b)=aE(x)+b \quad Var(ax+b)=a^{2}Var(x)$
$E(ax+by)=aE(x)+bE(y) \quad Var(ax+by)=a^{2}Var(x)+b^{2}Var(y)$</p>

<p><strong>思考：为什么加上b方差并没有发生变化呢？因为在变量中增加常数b只是将概率分布移动了一下，分布的形状并没有发生改变，所以b并没有在方差中起到作用。</strong></p>

<p>相互独立事件X和Y：</p>

<p>$E(X+Y)=E(X)+E(Y) \quad Var(X+Y)=Var(X)+Var(Y)$
$E(X-Y)=E(X)-E(Y) \quad Var(X-Y)=Var(X)+Var(Y)$</p>

<p><strong>思考：为什么$Var(X-Y)=Var(X)+Var(Y)$？可以随便拿数据验证之。[TODO]
记住，一个随机变量减去另一个随机变量得到的概率分布的方差是两个随机变量的方差之和，方差只会增加！下面两个图示演示了其结果
</strong></p>

<p><img src="varxplusy.png" alt="image" /></p>

<p><img src="varxminusy.png" alt="image" /></p>

<p>相互独立的随机变量与独立观测值之间的区别：</p>

<p><img src="independentobservation.png" alt="image" /></p>

<h4><center><strong>第二部分 分布</strong></center></h4>

<p>1.概率质量函数PMF(Probability Mass Function)：数据集中数据值到它的概率的映射函数。直方图是各个值出现的频数，如果将频数除以样本总数，得到概率，归一化之后的直方图就是PMF。</p>

<p><img src="pmf.png" alt="image" /></p>

<p>2.累积分布函数CDF(Cumulative Distribution Function)：数据集中数据值到它在分布中概率的累积值的映射函数。例如，
CDF(0) = 0; CDF(1) = 0.2; CDF(2) = 0.6; CDF(3) = 0.8; CDF(4) = 0.8; CDF(5) = 1，它的CDF图为一个阶跃函数：</p>

<p><img src="cdf.png" alt="image" /></p>

<p>3.指数分布(exponential distribution)：一种连续分布。举例来说，观察一系列事件之间的间隔时间，若事件在每个时间点发生的概率相同，那么间隔时间的分布就近似指数分布。指数分布的CDF如下：</p>

<p>$$
CDF(x)=1-e^{&ndash;\lambda x}
$$</p>

<p>参数$\lambda$决定了指数分布的形状，通常，指数分布的均值是$\frac{1}{\lambda}$，中位数是$\frac{log(2)}{\lambda}$。下图为$\lambda=2$的指数分布图：</p>

<p><img src="edcdf.png" alt="image" /></p>

<p>如果判断一个分布是否是指数分布呢？一种办法是画出取对数之后的互补累积分布函数(CCDF=Complementary CDF=1-CDF(x))，CCDF是一条斜率为$&ndash;\lambda$的直线，原因如下：</p>

<p>$$
y=CCDF(x)=1-CDF(x)=e^{&ndash;\lambda x} \quad => \quad log(y)=&ndash;\lambda x
$$</p>

<p>4.正态分布(Normal Distribution)：又叫高斯分布，是最常用的分布。对于正态分布的CDF还没有一种准确的表达，最常用的一种形式是以误差函数(error function)来表示，它是一个特殊的函数，表示为erf(x)：</p>

<p>$$
CDF(x)=\frac{1}{2}[1+erf(\frac{x-\mu}{\sigma \sqrt{2}})] \quad erf(x)=\frac{2}{\sqrt{\pi}}\int_{0}^{x}e^{-r^{2}}dt
$$</p>

<p>其中，参数$\mu$和$\sigma$分别决定了正态分布的均值和标准差。下图为$\mu=2.0$和$\sigma=0.5$的正态分布的CDF图：</p>

<p><img src="ndcdf.png" alt="image" /></p>

<p>根据大数定理，当我们处理大样本数据集(超过30个数据)，并且重复地从总体中抽取样本时，得到的数值分布就接近正态分布曲线。正态分布以均值为中心完全对称。</p>

<p>关于正态分布有一个重要的结论，对任何数值分布来说(不论它的均值和标准差)，只要数值是正态分布，那么几乎100%的数值都分布在均值的-3到3个标准差之间。下面是正态曲线下数值的分布情况：</p>

<p><img src="nd.png" alt="image" /></p>

<p>从中可以看出，在均值与1个标准差之间大概有34%的数值分布，在1个标准差和2个标准差之间大概有13%的数值分布，在2个标准差和3个标准差之间大概有2.1%的数值分布。</p>

<p><a href="http://wikipedia.org/wiki/Log-normal_distribution">对数正态分布</a>：如果一组数据取对数之后服从正态分布，那么我们就称其服从对数正态分布。对数正态分布的 CDF 跟正态分布一样, 只是用 logx 代替原来的 x:</p>

<p>$$
CDF<em>{lognormal}(x) = CDF</em>{normal}(log x)
$$</p>

<p>对数正态分布的均值与标准差不再是是$\mu$和$\sigma$了。可以证明,成人体重的分布是近似对数正态的。</p>

<h4><center><strong>第三部分 描述性统计量</strong></center></h4>

<p>1.描述数据的集中趋势：均值(mean)，中位数(median)，众数(mode)，加权平均数</p>

<p>百分位点(percentile points)：中位数(Q2)就是50百分位点，Q1为25百分位点(lower quartile)，Q3为75百分位点(upper quartile)，经常使用Q3-Q1=IQR(interquartile range，四分差或四分位数)来检查分布是否对称。</p>

<p>[如果要计算一组数中的某个百分位数，一般比较好的排序方法是选择排序；当然，如果是计算该组数的特殊的百分位数，例如中位数，有其他更好地方法能够在线性时间内得到，之后我对做一些相关问题的研究，暂且说明一下]</p>

<p>2.描述数据的变异性：极差(range)，标准差(standard deviation,简称s或者SD)，方差(deviation)</p>

<p>标准差的计算公式：
$$
s=\sqrt{\frac{\Sigma(X-\bar{X})<sup>2</sup>}{n-1}}
$$</p>

<p><strong>s是总体标准差的无偏估计，如果根号内部分母改成了n则是有偏估计</strong>，详细证明参见：<a href="http://en.wikipedia.org/wiki/Bias_of_an_estimator">http://en.wikipedia.org/wiki/Bias_of_an_estimator</a></p>

<p>标准差和方差的异同：<strong>它们都是用来反映数据集中数据的变异性或者离散度的度量，但是标准差以原有的计算单位存在，然而方差以平方单位存在，前者在实际中更加具有意义</strong>。例如，某高校的男生的平均身高是170cm，标准差是5cm，那么说明该校男生的身高与均值的差异大概就是5cm，换成方差来解释的话就不好陈述了。</p>

<p>使用有偏估计其实也可，但是最好使用无偏估计，我记得Coursera Machine Learning课中Andrew Ng曾经提到过，实际编码中其实还是使用有偏估计，因为它们在样本数据很大的时候其实结果没多大影响。</p>

<p>3.数据集的图形化显示：直方图，饼图，线图，柱形图，条形图，茎叶图等</p>

<p>数据分布的差异性描述：平均值，变异性，峰度(kurtosis)，偏度(skewness)</p>

<p>峰值可能有多个，比如双峰或者多峰等。偏度有一个计算公式，由Pearson发明的，他同时也是相关系数的发明者，偏度虽有正负之分，但是绝对值越大说明图形越偏。</p>

<p>$$
SK=\frac{3(\bar{X}-M)}{s},\quad M=Median,\bar{X}=Mean,s=SD
$$</p>

<p>4.相关系数(correlation coefficient)是两个变量之间<strong>线性关系</strong>的数值型指标，取值范围是[-1,1]，大于0表示正相关，小于0表示负相关，可以用散点图来直接查看相关性。根据某些不成文的规则，一般高于0.6表示强相关，低于0.4表示弱相关，中间部分表示中度相关。</p>

<p>[<strong>Pearson相关系数考察的变量的属性是连续的，例如年龄，体重等，如果是离散型变量那么应该使用点二列相关系数</strong>]</p>

<p>注意两点：(1)<strong>相关系数反映的是只是线性关系！如果两个变量的相关系数为0，只能说明它们没有线性关系存在，但是可能存在其他的非线性关系！</strong>
(2)<strong>相关性和因果关系无关！</strong>例如，冰淇淋的消费量和犯罪率是正相关的，但是两者不存在任何因果关系！</p>

<p>相关系数的计算：</p>

<p>$$
r_{XY}=\frac{n\Sigma{XY}&ndash;\Sigma{X}\Sigma{Y}}{\sqrt{[n\Sigma{X<sup>2</sup>}&ndash;(\Sigma{X})<sup>2</sup>][n\Sigma{Y<sup>2</sup>}&ndash;(\Sigma{Y})<sup>2</sup>]}}
$$</p>

<p>决定系数：相关系数的平方，它表述一个变量的方差可以被另一个变量的方差来解释的百分比。</p>

<h4><center><strong>第四部分 假设检验</strong></center></h4>

<p>1.假设：一般假设就是一个“猜想”，它表述问题的一般陈述。假设检验是用于样本，然后才将结论一般化推广到总体中。</p>

<p>2.零假设(null hypothesis=$H_{0}$，或叫原假设)：它一般表示“正在研究的两个变量无关或者没有差异”这样的命题。例如，三年级学生的记忆力考试成绩与四年级学生记忆力考试成绩之间没有差异。</p>

<p><strong>(1)零假设是研究的起点，因为在没有信息的情况下，零假设就被看作是可以接受的真实状态。在这种假设下，我们认为观测到的效应是由偶然因素造成的。</strong>
<strong>(2)零假设也是研究的基准，也就是说在零假设成立的情况下，计算统计量，然后进行假设检验。这就类似反证法的思想。</strong></p>

<p>3.研究假设(research hypothesis=alternate hypothesis，或叫备择假设)：与零假设相对立的，认为变量之间有关系的假设。</p>

<p>研究假设分为有方向和无方向两种研究假设。无方向研究假设命题例子：三年级学生的记忆力考试成绩与四年级学生记忆力考试成绩之间有差异。有方向研究假设命题例子：三年级学生的记忆力考试成绩低于四年级学生记忆力考试成绩。</p>

<p>讨论有无方向的另一种形式是讨论单尾检验(one-tailed test)和双尾检验(two-tailed test)。</p>

<p>零假设与研究假设的区别：
(1)零假设表示两个变量没有差异或者没有关系，研究假设表示它们有关系或者有差异；
(2)零假设对应的是总体，而研究假设对应的是样本。我们是从总体中取出一部分样本进行检验，将得到的结论推广到总体中。
(3)因为总体不能直接检验(不现实，不经济或者不可能)，所以零假设只能间接检验，研究假设则可以直接检验。</p>

<!-- footnots -->




<!-- mathjax config similar to math.stackexchange -->


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>


<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>



]]></content>
  </entry>
  
</feed>
