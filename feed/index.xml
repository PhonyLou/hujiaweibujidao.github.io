<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Hujiawei Bujidao]]></title>
  <link href="http://hujiaweibujidao.github.io/feed" rel="self"/>
  <link href="http://hujiaweibujidao.github.io/"/>
  <updated>2014-07-01T11:01:25+08:00</updated>
  <id>http://hujiaweibujidao.github.io/</id>
  <author>
    <name><![CDATA[hujiawei]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C9 Graphs]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-graphs/"/>
    <updated>2014-07-01T11:30:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-graphs</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(9)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-9-from-a-to-b-with-edsger-and-friendscenter"><center>Chapter 9: From A to B with Edsger and Friends</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<h4 id="section">图的总结</h4>

<p>Todo List</p>

<p>1.邻接矩阵和邻接表</p>

<p>2.DFS和BFS</p>

<p>3.DFS的应用：拓扑排序和有向无环图的强连通分量</p>

<p>4.最短路径：Dijkstra，Bellman-Ford，Floyd-Warshall等</p>

<p>5.最小生成树：Prim，Kruskal</p>

<p>6.网络流：最大流，最小割，二分图等</p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-graphs/">http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-graphs/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C8 Dynamic Programming]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-dynamic-programming/"/>
    <updated>2014-07-01T11:20:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-dynamic-programming</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(8)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-8-tangled-dependencies-and-memoizationcenter"><center>Chapter 8 Tangled Dependencies and Memoization</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<p>3.<a href="http://book.douban.com/subject/4875278/">算法设计、分析与实现从入门到精通</a></p>

<p>大家都知道，动态规划算法一般都有两种实现方式：</p>

<p><strong>1.直接自顶向下实现递归式，并将中间结果保存，这叫备忘录法；</strong></p>

<p><strong>2.将递归式翻转，自底向上地迭代，将结果保存在某个数据结构中。</strong></p>

<p>编程有一个原则<code>DRY=Don’t Repeat Yourself</code>，就是说你的代码不要重复来重复去的，这个原则同样可以用于理解动态规划，动态规划除了满足最优子结构，它还存在子问题重叠的性质，我们不能重复地去解决这些子问题，所以我们将子问题的解保存起来，类似缓存机制，之后遇到这个子问题时直接取出子问题的解。</p>

<p>举个简单的例子，斐波那契数列中的元素的计算，很简单，我们写下如下的代码：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">fib</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
</span><span class="line">    <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">2</span><span class="p">:</span> <span class="k">return</span> <span class="mi">1</span>
</span><span class="line">    <span class="k">return</span> <span class="n">fib</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="n">fib</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>好，来测试下，运行<code>fib(10)</code>得到结果69，不错，速度也还行，换个大的数字，试试100，这时你会发现，这个程序执行不出结果了，为什么？递归太深了！要计算的子问题太多了！</p>

<p>所以，我们需要改进下，我们保存每次计算出来的子问题的解，用什么保存呢？用Python中的dict！那怎么实现保存子问题的解呢？用Python中的装饰器！</p>

<p>如果不是很了解Python的装饰器，可以快速看下<a href="http://hujiaweibujidao.github.io/blog/2014/05/10/python-tips1/">这篇总结中关于装饰器的解释：Python Basics</a></p>

<p>修改刚才的程序，得到如下代码，定义一个函数<code>memo</code>返回我们需要的装饰器，这里用<code>cache</code>保存子问题的解，key是方法的参数，也就是数字<code>n</code>，值就是<code>fib(n)</code>返回的解。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">wraps</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">memo</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
</span><span class="line">    <span class="n">cache</span><span class="o">=</span><span class="p">{}</span>
</span><span class="line">    <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="n">args</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cache</span><span class="p">:</span>
</span><span class="line">            <span class="n">cache</span><span class="p">[</span><span class="n">args</span><span class="p">]</span><span class="o">=</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</span><span class="line">        <span class="k">return</span> <span class="n">cache</span><span class="p">[</span><span class="n">args</span><span class="p">]</span>
</span><span class="line">    <span class="k">return</span> <span class="n">wrap</span>
</span><span class="line">
</span><span class="line"><span class="nd">@memo</span>
</span><span class="line"><span class="k">def</span> <span class="nf">fib</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
</span><span class="line">    <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">2</span><span class="p">:</span> <span class="k">return</span> <span class="mi">1</span>
</span><span class="line">    <span class="k">return</span> <span class="n">fib</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="n">fib</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>重新运行下<code>fib(100)</code>，你会发现这次很快就得到了结果<code>573147844013817084101</code>，这就是动态规划的威力，上面使用的是第一种带备忘录的递归实现方式。</p>

<p><strong>带备忘录的递归方式的优点就是易于理解，易于实现，代码简洁干净，运行速度也不错，直接从需要求解的问题出发，而且只计算需要求解的子问题，没有多余的计算。但是，它也有自己的缺点，因为是递归形式，所以有限的栈深度是它的硬伤，有些问题难免会出现栈溢出了。</strong></p>

<p>于是，迭代版本的实现方式就诞生了！</p>

<p><strong>迭代实现方式有2个好处：1.运行速度快，因为没有用栈去实现，也避免了栈溢出的情况；2.迭代实现的话可以不使用dict来进行缓存，而是使用其他的特殊cache结构，例如多维数组等更为高效的数据结构。</strong></p>

<p>那怎么把递归版本转变成迭代版本呢？</p>

<p><strong>这就是递归实现和迭代实现的重要区别：递归实现不需要去考虑计算顺序，只要给出问题，然后自顶向下去解就行；而迭代实现需要考虑计算顺序，并且顺序很重要，算法在运行的过程中要保证当前要计算的问题中的子问题的解已经是求解好了的。</strong></p>

<p>斐波那契数列的迭代版本很简单，就是按顺序来计算就行了，不解释，关键是你可以看到我们就用了3个简单变量就求解出来了，没有使用任何高级的数据结构，节省了大量的空间。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">fib_iter</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span><span class="line">    <span class="k">if</span> <span class="n">n</span><span class="o">&lt;</span><span class="mi">2</span><span class="p">:</span> <span class="k">return</span> <span class="mi">1</span>
</span><span class="line">    <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span>
</span><span class="line">    <span class="k">while</span> <span class="n">n</span><span class="o">&gt;=</span><span class="mi">2</span><span class="p">:</span>
</span><span class="line">        <span class="n">c</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="n">b</span>
</span><span class="line">        <span class="n">a</span><span class="o">=</span><span class="n">b</span>
</span><span class="line">        <span class="n">b</span><span class="o">=</span><span class="n">c</span>
</span><span class="line">        <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span>
</span><span class="line">    <span class="k">return</span> <span class="n">c</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>斐波那契数列的变种经常出现在上楼梯的走法问题中，每次只能走一个台阶或者两个台阶，广义上思考的话，<strong>动态规划也就是一个连续决策问题，到底当前这一步是选择它(走一步)还是不选择它(走两步)呢?</strong></p>

<p>其他问题也可以很快地变相思考发现它们其实是一样的，例如求二项式系数<code>C(n,k)</code>，杨辉三角(求从源点到目标点有多少种走法)等等问题。</p>

<p>二项式系数<code>C(n,k)</code>表示从n个中选k个，假设我们现在n个中的第1个，考虑是否选择它。如果选择它的话，那么我们还需要从剩下的n-1个中选k-1个，即<code>C(n-1,k-1)</code>；如果不选择它的话，我们需要从剩下的n-1中选k个，即<code>C(n-1,k)</code>。所以，<code>C(n,k)=C(n-1,k-1)+C(n-1,k)</code>。</p>

<p>结合前面的装饰器，我们很快便可以实现求二项式系数的递归实现代码，其中的<code>memo</code>函数完全没变，只是在函数<code>cnk</code>前面添加了<code>@memo</code>而已，就这么简单！</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">wraps</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">memo</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
</span><span class="line">    <span class="n">cache</span><span class="o">=</span><span class="p">{}</span>
</span><span class="line">    <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="n">args</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cache</span><span class="p">:</span>
</span><span class="line">            <span class="n">cache</span><span class="p">[</span><span class="n">args</span><span class="p">]</span><span class="o">=</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</span><span class="line">        <span class="k">return</span> <span class="n">cache</span><span class="p">[</span><span class="n">args</span><span class="p">]</span>
</span><span class="line">    <span class="k">return</span> <span class="n">wrap</span>
</span><span class="line">
</span><span class="line"><span class="nd">@memo</span>
</span><span class="line"><span class="k">def</span> <span class="nf">cnk</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="p">):</span>
</span><span class="line">    <span class="k">if</span> <span class="n">k</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="mi">1</span> <span class="c">#the order of `if` should not change!!!</span>
</span><span class="line">    <span class="k">if</span> <span class="n">n</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">return</span> <span class="n">cnk</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">)</span><span class="o">+</span><span class="n">cnk</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>它的迭代版本也比较简单，这里使用了<code>defaultdict</code>，略高级的数据结构，和dict不同的是，当查找的key不存在对应的value时，会返回一个默认的值，这个很有用，下面的代码可以看到。</p>

<p>如果不了解<code>defaultdict</code>的话可以看下<a href="http://blog.jobbole.com/65218/">这篇文章：Python中的高级数据结构</a></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
</span><span class="line">
</span><span class="line"><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span>
</span><span class="line"><span class="n">C</span><span class="o">=</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span class="line"><span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
</span><span class="line">    <span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
</span><span class="line">    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
</span><span class="line">        <span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">]</span><span class="o">=</span><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">col</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">col</span><span class="p">]</span>
</span><span class="line">
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="p">])</span> <span class="c">#120</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>杨辉三角大家都熟悉，在国外这个叫<code>Pascal Triangle</code>，它和二项式系数特别相似，看下图，除了两边的数字之外，里面的任何一个数字都是由它上面相邻的两个元素相加得到，想想<code>C(n,k)=C(n-1,k-1)+C(n-1,k)</code>不也就是这个含义吗?</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/sanjiao.png" alt="image" /></p>

<p>所以说，顺序对于迭代版本的动态规划实现很重要，下面举个实例，用动态规划解决有向无环图的单源最短路径问题。假设有如下图所示的图，当然，我们看到的是这个有向无环图经过了拓扑排序之后的结果，从a到f的最短路径用灰色标明了。</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/dag_sp.png" alt="image" /></p>

<p>好，怎么实现呢? </p>

<p><strong>我们有两种思考方式：</strong></p>

<p><strong>1.”去哪里?”：我们顺向思维，首先假设从a点出发到所有其他点的距离都是无穷大，然后，按照拓扑排序的顺序，从a点出发，接着更新a点能够到达的其他的点的距离，那么就是b点和f点，b点的距离变成2，f点的距离变成9。因为这个有向无环图是经过了拓扑排序的，所以按照拓扑顺序访问一遍所有的点(到了目标点就可以停止了)就能够得到a点到所有已访问到的点的最短距离，也就是说，当到达哪个点的时候，我们就找到了从a点到该点的最短距离，拓扑排序保证了后面的点不会指向前面的点，所以访问到后面的点时不可能再更新它前面的点的最短距离！这种思维方式的代码实现就是迭代版本。</strong></p>

<p><strong>这里涉及到了拓扑排序，我的博客中还没有讲解，所以下面的代码已经将输入的点进行了拓扑排序，待我更新了图算法那篇文章再来更新这里的代码，谅解。</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">topsort</span><span class="p">(</span><span class="n">W</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="n">W</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">dag_sp</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
</span><span class="line">    <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="n">u</span><span class="p">:</span><span class="nb">float</span><span class="p">(</span><span class="s">&#39;inf&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">W</span><span class="p">}</span> <span class="c">#</span>
</span><span class="line">    <span class="n">d</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">topsort</span><span class="p">(</span><span class="n">W</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="n">u</span> <span class="o">==</span> <span class="n">t</span><span class="p">:</span> <span class="k">break</span>
</span><span class="line">        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">W</span><span class="p">[</span><span class="n">u</span><span class="p">]:</span>
</span><span class="line">            <span class="n">d</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">v</span><span class="p">],</span> <span class="n">d</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">+</span> <span class="n">W</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">v</span><span class="p">])</span>
</span><span class="line">    <span class="k">return</span> <span class="n">d</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
</span><span class="line">
</span><span class="line"><span class="c">#邻接表</span>
</span><span class="line"><span class="n">W</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:{</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">:</span><span class="mi">9</span><span class="p">},</span><span class="mi">1</span><span class="p">:{</span><span class="mi">2</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">:</span><span class="mi">6</span><span class="p">},</span><span class="mi">2</span><span class="p">:{</span><span class="mi">3</span><span class="p">:</span><span class="mi">7</span><span class="p">},</span><span class="mi">3</span><span class="p">:{</span><span class="mi">4</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">:</span><span class="mi">3</span><span class="p">},</span><span class="mi">4</span><span class="p">:{</span><span class="mi">5</span><span class="p">:</span><span class="mi">4</span><span class="p">},</span><span class="mi">5</span><span class="p">:{}}</span>
</span><span class="line"><span class="n">s</span><span class="p">,</span><span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span>
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="n">dag_sp</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">t</span><span class="p">))</span> <span class="c">#7</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>用图来表示计算过程就是下面所示：</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/dag_sp_iter.png" alt="image" /></p>

<p><strong>2.”从哪里来?”：我们逆向思维，目标是要到f，那从a点经过哪个点到f点会近些呢?只能是求解从a点出发能够到达的那些点哪个距离f点更近，这里a点能够到达b点和f点，f点到f点距离是0，但是a到f点的距离是9，可能不是最近的路，所以还要看b点到f点有多近，看b点到f点有多近就是求解从b点出发能够到达的那些点哪个距离f点更近，所以又绕回来了，也就是递归下去，直到我们能够回答从a点经过哪个点到f点会更近。这种思维方式的代码实现就是递归版本。</strong></p>

<p>这种情况下，不需要输入是经过了拓扑排序的，所以你可以任意修改输入<code>W</code>中节点的顺序，结果都是一样的，而上面采用迭代实现方式必须要是拓扑排序了的，从中你就可以看出迭代版本和递归版本的区别了。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">wraps</span>
</span><span class="line"><span class="k">def</span> <span class="nf">memo</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
</span><span class="line">    <span class="n">cache</span><span class="o">=</span><span class="p">{}</span>
</span><span class="line">    <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="n">args</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cache</span><span class="p">:</span>
</span><span class="line">            <span class="n">cache</span><span class="p">[</span><span class="n">args</span><span class="p">]</span><span class="o">=</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</span><span class="line">            <span class="c"># print(&#39;cache {0} = {1}&#39;.format(args[0],cache[args]))</span>
</span><span class="line">        <span class="k">return</span> <span class="n">cache</span><span class="p">[</span><span class="n">args</span><span class="p">]</span>
</span><span class="line">    <span class="k">return</span> <span class="n">wrap</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">rec_dag_sp</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
</span><span class="line">    <span class="nd">@memo</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="n">u</span> <span class="o">==</span> <span class="n">t</span><span class="p">:</span> <span class="k">return</span> <span class="mi">0</span>
</span><span class="line">        <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">v</span><span class="p">]</span><span class="o">+</span><span class="n">d</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">W</span><span class="p">[</span><span class="n">u</span><span class="p">])</span>
</span><span class="line">    <span class="k">return</span> <span class="n">d</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="c">#邻接表</span>
</span><span class="line"><span class="n">W</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:{</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">:</span><span class="mi">9</span><span class="p">},</span><span class="mi">1</span><span class="p">:{</span><span class="mi">2</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">:</span><span class="mi">6</span><span class="p">},</span><span class="mi">2</span><span class="p">:{</span><span class="mi">3</span><span class="p">:</span><span class="mi">7</span><span class="p">},</span><span class="mi">3</span><span class="p">:{</span><span class="mi">4</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">:</span><span class="mi">3</span><span class="p">},</span><span class="mi">4</span><span class="p">:{</span><span class="mi">5</span><span class="p">:</span><span class="mi">4</span><span class="p">},</span><span class="mi">5</span><span class="p">:{}}</span>
</span><span class="line"><span class="n">s</span><span class="p">,</span><span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span>
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="n">rec_dag_sp</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">t</span><span class="p">))</span> <span class="c">#7</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>用图来表示计算过程就是下面所示：</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/dag_sp_rec.png" alt="image" /></p>

<p>下面是参考内容1对DAG求单源最短路径的动态规划问题的总结，比较难理解，不知道我自己理解得对不对，可以忽视注释，:-)</p>

<p><img src="http://hujiaweibujidao.github.io/images/algos/dp_summary.png" alt="image" /></p>

<p>好，我们差不多搞清楚了动态规划的本质以及两种实现方式的优缺点，下面我们来实践下，举最常用的例子：<a href="http://hujiaweibujidao.github.io/blog/2014/05/18/matrix-chain/">矩阵链乘问题，内容较多，所以请点击链接过去阅读完了之后回来看总结</a>！</p>

<p>OK，希望我把动态规划将清楚了，总结下：<strong>动态规划其实就是一个连续决策的过程，每次决策我们可能有多种选择(二项式系数和0-1背包问题中我们只有两个选择，DAG图的单源最短路径中我们的选择要看点的出边或者入边，矩阵链乘问题中就是矩阵链可以分开的位置总数…)，我们每次选择最好的那个作为我们的决策。所以，动态规划的时间复杂度其实和这两者有关，也就是子问题的个数以及子问题的选择个数，一般情况下动态规划算法的时间复杂度就是两者的乘积。动态规划有两种实现方式：一种是带备忘录的递归形式，这种方式直接从原问题出发，遇到子问题就去求解子问题并存储子问题的解，下次遇到的时候直接取出来，问题求解的过程看起来就像是先自顶向下地展开问题，然后自下而上的进行决策；另一个实现方式是迭代方式，这种方式需要考虑如何给定一个子问题的求解方式，使得后面求解规模较大的问题是需要求解的子问题都已经求解好了，它的缺点就是可能有些子问题不要算但是它还是算了，而递归实现方式只会计算它需要求解的子问题。</strong></p>

<p>如果你感觉你有所顿悟，来试试写写<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/longest-common-subsequence/">最长公共子序列吧，这篇文章中给出了Python版本的5种实现方式</a>哟！</p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-dynamic-programming/">http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-dynamic-programming/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C7 Greedy]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-greedy/"/>
    <updated>2014-07-01T11:10:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-greedy</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(7)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-7-greed-is-good-prove-itcenter"><center>Chapter 7: Greed is good? Prove it!</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-greedy/">http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-greedy/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C6 Divide and Combine and Conquer]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-divide-and-combine-and-conquer/"/>
    <updated>2014-07-01T11:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-divide-and-combine-and-conquer</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(6)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-6-divide-and-combine-and-conquercenter"><center>Chapter 6: Divide and Combine and Conquer</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-divide-and-combine-and-conquer/">http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-divide-and-combine-and-conquer/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C5 Traversal]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-traversal/"/>
    <updated>2014-07-01T10:50:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-traversal</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(5)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-5-traversalcenter"><center>Chapter 5: Traversal</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-traversal/">http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-traversal/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C4 Induction and Recursion and Reduction]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-induction/"/>
    <updated>2014-07-01T10:40:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-induction</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(4)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-4-induction-and-recursion-and-reductioncenter"><center>Chapter 4: Induction and Recursion and Reduction</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-induction/">http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-induction/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C3 Counting 101]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-counting-101/"/>
    <updated>2014-07-01T10:30:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-counting-101</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(3)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-3-counting-101center"><center>Chapter 3: Counting 101</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-counting-101/">http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-counting-101/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C2 The basics]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-the-basics/"/>
    <updated>2014-07-01T10:20:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-the-basics</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(2)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-2-the-basicscenter"><center>Chapter 2: The basics</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-the-basics/">http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-the-basics/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Algorithms - C1 Introduction]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-introduction/"/>
    <updated>2014-07-01T10:10:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-introduction</id>
    <content type="html"><![CDATA[<p><strong><center>Python算法设计篇(1)</center></strong>
<strong><center>逸夫图书馆, 2014/7/1</center></strong></p>

<h3 id="centerchapter-1-introductioncenter"><center>Chapter 1: Introduction</center></h3>

<p>参考内容：</p>

<p>1.<a href="http://link.springer.com/book/10.1007%2F978-1-4302-3238-4">Python Algorithms: Mastering Basic Algorithms in the Python Language</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms">算法导论</a></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-introduction/">http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-introduction/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Forza Azzurri]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/06/22/Forza-Azzurri/"/>
    <updated>2014-06-22T22:30:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/06/22/Forza-Azzurri</id>
    <content type="html"><![CDATA[<p>正值巴西世界杯之际，特此上张图，保佑我大呆梨能够最终捧得大力神杯回家！</p>

<p><img src="http://hujiaweibujidao.github.io/images/pics/italy.jpg" alt="image" /></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/06/22/Forza-Azzurri/">http://hujiaweibujidao.github.io/blog/2014/06/22/Forza-Azzurri/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Thanks to 360 CDN]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/06/22/thanks-to-360-cdn/"/>
    <updated>2014-06-22T10:40:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/06/22/thanks-to-360-cdn</id>
    <content type="html"><![CDATA[<p>由于众所周知的原因，最近各种网站(以Google、Dropbox为首)都纷纷被墙，作为码农，简直要了俺们的命根子啊，没办法生在天朝也就只能发发牢骚而已，可是，最令人无奈的是Github也时常被拒之于墙外，这可让我这个把个人博客搭在Github上的小屌丝更是吓得心惊胆战，难道真的是要闭关锁国的节奏吗？</p>

<p>有人说的对，一开始不知道为什么Evernote在中国国内要另搞一个印象笔记，现在想想这招真是太聪明了，Dropbox要学着点了，但即使是学过来了，面对国内各种免费送N个T云空间的网盘你的竞争优势有多大呢？</p>

<p>OK，不发牢骚了，因为Google被墙的厉害，而且博客中不少使用了Google API(js库和字体库)，导致博客前段时间访问速度特别慢，所以考完我就来整理整理下，这里要感谢<a href="http://libs.useso.com/">360网站卫士提供的常用前端公共库CDN服务</a>，你们总是能够推出关乎码农们痛痒的东西，永远支持你们！</p>

<p>主要修改下面两处即可：</p>

<p>文件： <code>source/_includes</code>目录下的<code>head.html</code>，修改如下：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="html"><span class="line"><span class="c">&lt;!--</span>
</span><span class="line"><span class="c">&lt;script src=&quot;//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js&quot;&gt;&lt;/script&gt;</span>
</span><span class="line"><span class="c">--&gt;</span>
</span><span class="line"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&#39;text/javascript&#39;</span> <span class="na">src=</span><span class="s">&#39;http://ajax.useso.com/ajax/libs/jquery/1.7.2/jquery.min.js?ver=3.4.2&#39;</span><span class="nt">&gt;&lt;/script&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>文件： <code>source/_includes</code>目录下的<code>header.html</code>，修改如下：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="html"><span class="line"><span class="c">&lt;!-- 注释掉下面的js --&gt;</span>
</span><span class="line"><span class="c">&lt;!--</span>
</span><span class="line"><span class="c">&lt;script src=&quot;//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js&quot;&gt;&lt;/script&gt;</span>
</span><span class="line"><span class="c">--&gt;</span>
</span><span class="line"><span class="c">&lt;!-- 添加下面的js --&gt;</span>
</span><span class="line"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&#39;text/javascript&#39;</span> <span class="na">src=</span><span class="s">&#39;http://ajax.useso.com/ajax/libs/jquery/1.7.2/jquery.min.js?ver=3.4.2&#39;</span><span class="nt">&gt;&lt;/script&gt;</span>
</span><span class="line"><span class="c">&lt;!-- 省略部分代码 --&gt;</span>
</span><span class="line"><span class="c">&lt;!-- 我没有使用Google analytics，所以注释下面一行代码(略有删减) --&gt;</span>
</span><span class="line"><span class="c">&lt;!--</span>
</span><span class="line"><span class="c">inlcude google_analytics.html</span>
</span><span class="line"><span class="c">--&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>文件： <code>source/_includes/custom</code>目录下的<code>head.html</code>，修改如下：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="html"><span class="line"><span class="c">&lt;!-- 注释掉下面的css --&gt;</span>
</span><span class="line"><span class="c">&lt;!--Fonts from Google&quot;s Web font directory at http://google.com/webfonts --&gt;</span>
</span><span class="line"><span class="c">&lt;!--</span>
</span><span class="line"><span class="c">&lt;link href=&quot;http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt;</span>
</span><span class="line"><span class="c">&lt;link href=&quot;http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt;</span>
</span><span class="line"><span class="c">--&gt;</span>
</span><span class="line"><span class="c">&lt;!-- 添加下面的css --&gt;</span>
</span><span class="line"><span class="nt">&lt;link</span> <span class="na">href=</span><span class="s">&quot;http://fonts.useso.com/css?family=PT+Serif:regular,italic,bold,bolditalic&quot;</span> <span class="na">rel=</span><span class="s">&quot;stylesheet&quot;</span> <span class="na">type=</span><span class="s">&quot;text/css&quot;</span><span class="nt">&gt;</span>
</span><span class="line"><span class="nt">&lt;link</span> <span class="na">href=</span><span class="s">&quot;http://fonts.useso.com/css?family=PT+Sans:regular,italic,bold,bolditalic&quot;</span> <span class="na">rel=</span><span class="s">&quot;stylesheet&quot;</span> <span class="na">type=</span><span class="s">&quot;text/css&quot;</span><span class="nt">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>OK，大功告成，更新文件，重新打开，你会瞬间感觉世界又重新美好了！</p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/06/22/thanks-to-360-cdn/">http://hujiaweibujidao.github.io/blog/2014/06/22/thanks-to-360-cdn/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dog Face Recognition]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/06/09/Dog-Face-Recognition/"/>
    <updated>2014-06-09T21:30:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/06/09/Dog-Face-Recognition</id>
    <content type="html"><![CDATA[<h3 id="center-center"><center>模式识别大作业-狗脸识别</center></h3>
<center> 胡家威 计研135班 2013210902 </center>

<h4 id="section">1. 题目要求</h4>

<h5 id="pca">(1)PCA狗脸识别</h5>

<p>采用PCA狗脸识别的方法完成下面的实验。图像特征可以采用灰度像素值、颜色直方图等。</p>

<p>1.用每个品种的一半数据做训练,另一半数据做测试(可以前40张图像作为训练，后40张图像作为测试)。采用K近邻分类(必做:K=1，选做:K=3,5)，分析选取不同的主分量个数，对识别率和虚警率的影响。</p>

<p>2.评价该方法的性能</p>

<p>3.计算每个品种的正确识别率</p>

<p>4.进行开集测试(见题目要求3)</p>

<h5 id="fisher">(2)Fisher狗脸识别</h5>

<p>采用线性判别准则的方法进行实验。</p>

<p>1.用每个品种的一半数据做训练，另一半数据做测试(可以前40张图像作为训练，后40张图像作为测试)。给出用fisherface方法得到的识别率。</p>

<p>2.同PCA一样，评价该方法的性能 </p>

<p>3.进行开集测试(见题目要求3)</p>

<p>4.比较这两个方法的优缺点</p>

<h5 id="section-1">(3)开集测试</h5>

<p>图像数据中还有80张负样本(neg，猫脸)，即非狗脸图像。此时需要给出一个合理的拒识方式来判断 某张图像是否属于训练的10个品种。请设计一个合理的拒识方式(最简单的方式是对测试图像到训练 图像的最近距离设定一个阈值)并对400张狗脸测试图像和80张猫脸测试图像进行识别(11个类别，最后一个为neg类)，观察阈值不同时对识别结果的影响。</p>

<h5 id="section-2">(4)选作部分</h5>

<p>1.(选做)根据上面的评价比较，给出改善，并且对新方法再进行评价</p>

<p>2.可以采用更加复杂的特征如HOG，BOW特征，也可以在分类方法上采用别的方式(如SVM、层级式分类)而不是K邻分类。鼓励同学们创新。</p>

<p>3.需要有曲线，表格和测试数据的说明</p>

<h4 id="section-3">2.实验内容</h4>

<p>实验总体介绍：本次实验我共尝试使用了三种不同的图像特征进行比较：(1)灰度像素值； (2)LBP特征； (3)HOG特征。每一种图像特征又结合下面四种算法：(1)PCA； (2)Fisher； (3)SVM； (4)HOSVD 来进行分类，并且采用了开集测试和10折交叉验证的方式分析算法的正确率。下面是实验的分析过程和分析结果</p>

<h5 id="section-4">2.1 特征选择和提取</h5>

<p>下图显示了要识别的10个品种的狗，每个品种的狗只选择了其中一张图像，下文中提到的狗的品种编号按照下图中从左到右从上到下的方式进行索引。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/gallery_dog_exp.jpg" alt="image" /></p>

<p>下图显示了实验使用的三种特征，从左到右分别是原图(第一条狗的第71张图像)以及它对应的灰度图、LBP特征图、HOG特征图，得到的数据分别存储在数据结构gray,lbp和hog中，然后保存为mat格式的文件，因为数据量比较大，每次重新提取会耗费大量时间，所以采用先保存在需要的时候再进行加载的方式。对于一张大小为144x144的图像，灰度像素特征共有144x144个；LBP特征采用的半径是1，取8个领域，所以特征共有142x142个；HOG特征采用的cell的大小为9，所以特征共有9x9=81个。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/dog_4imgs.png" alt="image" /></p>

<h5 id="section-5">2.2 特征值和特征脸的观察</h5>

<p>下图显示了对所有灰度图像的特征值进行分析得到的结果，左图显示了各个特征值在总特征值之和中所占的比例，很明显只有前面几个特征值具有较高的比例，后面的特征基本上都是冗余的；右图显示了特征值的累计之和在总特征值之和中所占的比例，通过观察也不难发现前面一些特征的累加便可达到90%以上的比例。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/eigen.png" alt="image" /></p>

<p>假设保证使用90%作为选择主成分数目的阈值标准，那么对于灰度像素特征，通过计算得到共需要前95个特征。对于LBP特征和HOG特征同样可以进行上面的分析，下面是HOG特征的结果，因为总共只有81个特征，所以计算很快，但是要达到90%以上的比例需要29个特征。另外，LBP特征因为它的特殊性，它需要649个特征才能达到90%以上的比例。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/eigen_hog.png" alt="image" /></p>

<p>下图显示了灰度特征下得到的狗的前16个特征脸，为了增强可视性，我使用了方法<code>colormap(jet(256))</code>提高显示效果。从结果中可以看出，第一个特征脸就很像一只小狗，其他的特征脸因为抓住的是狗脸的其他特征所以只是隐隐约约可见狗脸的轮廓。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/eigenface_gray.png" alt="image" /></p>

<p>同样的，也可以查看下LBP特征下的特征脸，下面是前16个特征脸的显示结果，从结果中可以看出，LBP很好地抓住了狗脸部眼睛和鼻子的特征。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/eigenface_lbp.png" alt="image" /></p>

<h5 id="section-6">2.3 性能测试方式选择</h5>

<p>本次实验尝试了两种性能评价方法，一种是题目要求的取前40张图像作为训练，取后40张图像作为测试；另一种是常用的10折交叉验证的方法，每次从每个品种中选择8张(80/10=8)图像作为测试，其他的72张图像作为训练。例如，对于HOG特征，采用PCA和K近邻算法结合的狗脸识别得到的结果如下，可以看出一般开集测试的准确率都低于它对应的正样本测试得到的准确率，此外，采用交叉验证得到的准确率也要略高于第一种性能测试方式。另外，从理论上来说，交叉验证的性能评价方式更加科学，结果准确性更高，所以后面的结果大部分都采用交叉验证的性能测试方式，只是对于SVM和HOSVD这类复杂的运行时间长的算法采用第一种性能测试方式。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/hog_pca_k.png" alt="image" /></p>

<h5 id="section-7">2.4 开集测试的阈值选择</h5>

<p>上面的结果使用的阈值是负样本中的采用欧式距离度量情况下得到的最大距离M和最小距离m的平均值(M+m)/2，实验过程中我只尝试了两种不同的阈值比较，一个是使用最大距离M(使用最小距离m的话效果非常差，不作为比较之中)；另一种便是使用均值(M+m)/2。下面是使用HOG特征在PCA和最近邻算法下得到的结果，左图是使用均值的情况，右图是使用最大距离的情况。两者的准确率分别是58.09%和62.05%，最大距离稍微高些，但是仔细观察最后一行和最后一列，对于使用均值距离容易出现很多狗被认为不是狗，对于最大距离容易出现很多猫被认为是狗！相比较而言，我认为后者的风险更大，所以我采用的阈值是均值。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/cv_threshold.png" alt="image" /></p>

<h5 id="pca-1">2.5 PCA狗脸识别</h5>

<p>如果使用PCA以及K近邻算法进行狗脸识别，采用10折交叉验证方法对测试算法性能，对于不同的图像特征和K的取值得到下面的结果。从结果中可以看出，HOG特征的结果最优(平均都在60%以上)，其次是灰度像素特征(稳定在50%左右)，表现最差的是LBP特征(不超过30%)；在运行速度方面，HOG特征的运行速度最快，灰度像素特征和LBP特征的运行速度都比较慢。此外，对于不同的k近邻，HOG特征的结果差别不大，相当稳定；灰度像素特征受影响比较大，因为样本中图像的灰度差别比较大，同一个品种的狗的图像的灰度差别也比较大，甚至有些品种的狗本身就存在多种肤色的情况。[结果<code>A/B</code>分别表示对应的正样本测试和开集测试下的准确率，下同]</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/pca_k.png" alt="image" /></p>

<p>下图是对于灰度像素特征得到的性能图，左边是正样本测试的结果，右边是开集测试的结果。从图中可以看出，判断错误的情况还是比较多的，尤其是比较多的错判为2和5两个品种的狗，这两个品种的狗都是褐色的，在狗的颜色当中比较具有代表性。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/gray_cv.png" alt="image" /></p>

<p>下图是对于LBP特征得到的性能图，左边是正样本测试的结果，右边是开集测试的结果。从图中可以看出，很多狗都被错误地判断为1、5和10三个品种的狗，观察发现这三种狗的脸部形状、眼睛和鼻子的分布在狗当中比较具有代表性。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/lbp_cv.png" alt="image" /></p>

<p>下图是对于HOG特征得到的性能图，左边是正样本测试的结果，右边是开集测试的结果。从图中可以看出，后面4个品种的狗的脸部相似性比较高，观察发现这四种狗的毛发比较多，因为导致它们的HOG特征相似性比其他品种的狗要高一些。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/hog_cv.png" alt="image" /></p>

<p>下图是HOG特征在k=1的情况得到的各个品种的狗的识别准确率 [准确率比较容易得到，下面就不显示该类结果了]</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/precision.png" alt="image" /></p>

<h5 id="fisher-1">2.6 Fisher狗脸识别</h5>

<p>如果使用LDA以及K近邻算法进行狗脸识别，采用10折交叉验证方法对测试算法性能，对于不同的图像特征和K的取值得到下面的结果。HOG特征只有81个，数目小于N-C=((720-80)-10)=630，所以不能使用。从结果中可以看出，使用Fisher识别算法采用LBP特征比灰度像素特征更好些，在运行速度方面，两者的的运行速度差不多，但都比较慢。此外，对于不同的k近邻，灰度像素特征此时受影响程度不大，LBP特征受影响程度也不大。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/lda_k.png" alt="image" /></p>

<p>下图是对于灰度像素特征得到的性能图，左边是正样本测试的结果，右边是开集测试的结果。从图中可以看出，判断错误的情况基本上都是错判为品种5的狗，原因可能是品种5的狗在狗中是最为常见最为标准的样子。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/gray_lda_cv.png" alt="image" /></p>

<p>下图是对于LBP特征得到的性能图，左边是正样本测试的结果，右边是开集测试的结果。从图中可以看出，LBP特征在Fisher识别中的效果比PCA识别中的效果好很多，而且，通过右图可知拒识率相当高，也就是说虽然使用Fisher识别比PCA识别准确率高了不少，但是虚警率同样高了很多。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/lbp_lda_cv.png" alt="image" /></p>

<!--
下图是对于HOG特征得到的性能图，左边是正样本测试的结果，右边是开集测试的结果。从图中可以看出，后面4个品种的狗的脸部相似性比较高，观察发现这四种狗的毛发比较多，因为导致它们的HOG特征相似性比其他品种的狗要高一些。

![image](/images/ml/hog_lda_cv.png)
-->

<p>下图是灰度像素特征下得到的Fisher脸，下图的结果不容易看出的结果，部分图像隐约可见某个品种的狗脸轮廓，其中包括了狗的眼睛和鼻子。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/fisher_faces.png" alt="image" /></p>

<p><strong>与PCA狗脸识别对比</strong>：PCA识别的优点是速度快，Fisher略微慢些；在PCA中LBP特征准确率非常差，但是在Fisher中LBP特征的结果相当不错，超过了灰度像素特征；对于灰度像素特征，Fisher识别的准确率要比PCA识别的准确率要高，但两者将狗识别为非狗的情况都特别多；运行时间方面，两者的运行时间差不多。</p>

<h5 id="svm">2.7 SVM算法狗脸识别</h5>

<p>实验的过程中我分别测试了线性(linear)、多项式(polynomial)和径向基(RBF)三种不同核函数的SVM算法，经过测试之后我将参数C统一设置为20，以下是不同特征和核函数得到的结果。此外，因为SVM算法的训练需要比较长的时间，所以这里就不采用交叉验证的方式，而是采用第一种性能测试方式(一半训练另一半测试)。很明显，不同情况下的结果差别很大，例如，对于HOG特征，在线性SVM中得到的结果最好，接近90%，但是对于多项式和径向基核函数只能得到10%的准确率，这也说明了线性SVM虽然是最简单的SVM，但是在特定情况下没准是性能最好的SVM。 [尚不清楚三种特征在多项式核函数和径向基核函数的情况下都是10%的原因，不排除是不合适的参数造成]</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/svm.png" alt="image" /></p>

<h5 id="hosvd">2.8 HOSVD算法狗脸识别</h5>

<p>为了做进一步扩展，我选择了HOSVD算法，即高维奇异值分解算法来和其他算法的性能进行对比。HOSVD算法是SVD算法在高维空间的扩展，在人脸识别领域使用的也比较多，相关知识参考书籍《Matrix Methods in Data Mining and Pattern Recognition》。</p>

<p>PCA算法虽然实现上比较简单,但是在不同的环境(例如光照条件)和不同的人物表情下识别率比较低，所以后来就演变出了“张量脸”算法，即HOSVD算法，它基于下图所示的张量的Tuker分解。简言之，就是将狗脸图像的某种特征视为一个列向量，将同一个品种的狗的不同图像(视为狗的不同的表情)对应的列向量组合成一个矩阵，然后将不同品种的狗对应的矩阵组合成如下图所示的张量x。HOSVD算法就是对张量x进行分解，得到一个核心张量和几个其他正交阵，更加详细的讲解参考上面书籍。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/tensor_turker.png" alt="image" /></p>

<p>与PCA类似，它也需要给定一个主成分的参数，如果张量的维数太大的话计算机训练一个HOSVD的模型需要比较长的时间，所以，为了保证HOSVD算法能够在一定的时间内给出结果，它的输入图像不是原始的大小，而是缩小为72x72，在这样的情况下完成灰度像素特征下的HOSVD分解大概需要8分钟。考虑到运行时间过长，所以此时也改用第一种性能测试方式(一半训练另一半测试)。下面是不同的特征和k值得到的HOSVD算法的结果 [画线处表示结果未计算，可以看出其结果并不是最优的]</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/hosvd.png" alt="image" /></p>

<h4 id="section-8">3 实验总结</h4>

<p>本实验从特征的选择和提取开始，一步步经过特征值的分析以及对于性能评估方法和开集测试的阈值的选择，然后依次使用PCA识别、Fisher识别、SVM算法和HOSVD算法进行识别，分析算法的结果及其性能。通过对比各种算法的平均情况下的最好的结果，得到如下结果。从对比中可以看出，平均情况下表现最好的是SVM算法，而且是在HOG特征以及线性核函数的情况下表现最优；对于PCA识别，采用HOG特征最佳；对于Fisher识别，采用LBP特征最佳；而HOSVD算法需要的时间比SVM算法还多，但是性能并没有进一步提升，所以并不是该类问题的很好解决方案。</p>

<p><img src="http://hujiaweibujidao.github.io/images/ml/all.png" alt="image" /></p>

<p><strong>实验评价</strong>：</p>

<p>(1)本实验的最大亮点在于很好地对多个特征在多个不同算法上的结果进行分析和比较，而且大胆尝试了SVM算法和HOSVD算法，但是由于对这两个略微复杂的算法的理解能力不足，没能更好地解释得到的实验结果(例如多项式和径向基核函数会得到很低的准确率的原因)，也没能进一步通过调整参数使得这两个算法的性能进一步提升；</p>

<p>(2)实验过程中有效地结合使用两种性能测试方式缩短了实验时间(SVM和HOSVD算法使用一半训练另一半测试的方式)，但是在对算法的性能进行比较的时候没能详细地比较具体的运行时间；</p>

<p>(3)实验过程中的分析还算是比较清晰，按照一定的逻辑不断调整策略，但是在一些阈值的选择(例如开集测试的距离阈值)、参数的选择(SVM算法的核函数的参数)方面感觉没有方向性，不能按照一定的思路朝着更好的结果进行。另外，由于缺乏数字图像处理的能力，没能对图像进行一些预处理操作，例如截取狗脸的核心区域不但可以减少特征数目，而且肯定能够提高算法的准确率。</p>

<h4 id="section-9">参考资料：</h4>

<p>1.Pattern Recognition. Sergios Theodoridis</p>

<p>2.Introduction to Pattern Recognition: A Matlab Approach. Sergios Theodoridis</p>

<p>3.Matrix Methods in Data Mining and Pattern Recognition. Lars Eldén</p>

<p>4.Blog of Bytefish: <a href="http://bytefish.de/blog">http://bytefish.de/blog</a></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/06/09/Dog-Face-Recognition/">http://hujiaweibujidao.github.io/blog/2014/06/09/Dog-Face-Recognition/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSU beautiful scenery]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/20/csu-beautiful-scenery/"/>
    <updated>2014-05-20T09:11:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/20/csu-beautiful-scenery</id>
    <content type="html"><![CDATA[<p>在CSU经历了四年的青春，感谢母校的培养，感谢曾经一起欢笑的小伙伴们，想你们！</p>

<p><img src="http://hujiaweibujidao.github.io/images/pics/csupictures-004.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-005.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-006.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-007.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-008.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-010.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-011.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-012.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-013.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-018.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-029.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-017.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-022.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-023.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-025.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-026.jpg" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/pics/csupictures-032.jpg" alt="image" /></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/05/20/csu-beautiful-scenery/">http://hujiaweibujidao.github.io/blog/2014/05/20/csu-beautiful-scenery/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SS 4-Hypothesis Testing]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-4/"/>
    <updated>2014-05-19T23:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-4</id>
    <content type="html"><![CDATA[<p><strong><center>统计学那些事 Things of Statistics</center></strong>
<strong><center>逸夫图书馆, 2014/5/19</center></strong></p>

<hr />

<h4 id="center-center"><center>第四部分 假设检验</center></h4>

<p>1.假设：一般假设就是一个“猜想”，它表述问题的一般陈述。假设检验是用于样本，然后才将结论一般化推广到总体中。</p>

<p>2.零假设(null hypothesis=$H_{0}$，或叫原假设)：它一般表示“正在研究的两个变量无关或者没有差异”这样的命题。例如，三年级学生的记忆力考试成绩与四年级学生记忆力考试成绩之间没有差异。</p>

<p><strong>(1)零假设是研究的起点，因为在没有信息的情况下，零假设就被看作是可以接受的真实状态。在这种假设下，我们认为观测到的效应是由偶然因素造成的。</strong></p>

<p><strong>(2)零假设也是研究的基准，也就是说在零假设成立的情况下，计算统计量，然后进行假设检验。这就类似反证法的思想。</strong></p>

<p>3.研究假设(research hypothesis=alternate hypothesis，或叫备择假设)：与零假设相对立的，认为变量之间有关系的假设。</p>

<p>研究假设分为有方向和无方向两种研究假设。无方向研究假设命题例子：三年级学生的记忆力考试成绩与四年级学生记忆力考试成绩之间有差异。有方向研究假设命题例子：三年级学生的记忆力考试成绩低于四年级学生记忆力考试成绩。</p>

<p>讨论有无方向的另一种形式是讨论单尾检验(one-tailed test)和双尾检验(two-tailed test)。</p>

<p><strong>零假设与研究假设的区别：</strong></p>

<p><strong>(1)零假设表示两个变量没有差异或者没有关系，研究假设表示它们有关系或者有差异；</strong></p>

<p><strong>(2)零假设对应的是总体，而研究假设对应的是样本。我们是从总体中取出一部分样本进行检验，将得到的结论推广到总体中。</strong></p>

<p><strong>(3)因为总体不能直接检验(不现实，不经济或者不可能)，所以零假设只能间接检验，研究假设则可以直接检验。</strong></p>

<p>[To be Continued…]</p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-4/">http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-4/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SS 3-Multiple Random Variables and its Distribution]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-2/"/>
    <updated>2014-05-19T20:40:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-2</id>
    <content type="html"><![CDATA[<p><strong><center>统计学那些事 Things of Statistics</center></strong>
<strong><center>逸夫图书馆, 2014/5/19</center></strong></p>

<hr />

<h4 id="center-center"><center>第三部分 分布之多维随机变量及其分布</center></h4>

<p>很多情况下我们遇到的都是多维的随机变量，比如，对一个地区的儿童进行抽样统计，观察他们的身高H和体重W，样本空间S就是该地区的儿童，身高H和体重W都是定义在S上的随机变量，这里向量(H,W)就构成了二维随机向量(或者二维随机变量)，前面两节讨论的分布都是一维随机变量的分布。二维随机变量(X,Y)的性质不仅和X及Y的性质有关，还和它们的相关性有关，也就是前面提到的相关系数！</p>

<p>1.二维随机变量(X,Y)的分布函数(或者叫联合分布函数)</p>

<script type="math/tex; mode=display">F(x,y)=P(X \le x \cap Y \le y)=P(X \le x, Y \le y)</script>

<p>如果将二维随机变量看作是平面上随机点的坐标的话，那么分布函数F(x,y)在点(x,y)处的函数值就是以点(x,y)为顶点而位于该点左下方的无穷矩形域内的概率。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/mul_1.png" alt="image" /></p>

<p>分布函数的性质：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/mul_2.png" alt="image" /></p>

<p>如果(X,Y)只有有限对可取的值那么就是二维离散型随机变量(X,Y)，它的分布律(或者随机变量X和Y的联合分布律)：</p>

<script type="math/tex; mode=display">P(X=x_{i},Y=y_{j})=p_{ij},i,j=1,2,..., \quad (\Sigma_{i=0}^{\infty}\Sigma_{j=0}^{\infty}p_{ij}=1)</script>

<p>则有：<script type="math/tex">F(x,y)=P(X \le x, Y \le y)=\Sigma_{x \le x_{i}}\Sigma_{y \le y_{j}}p_{ij}</script></p>

<p>如果(X,Y)的值是由非负函数f(x,y)确定的，那么就是二维连续型随机变量(X,Y)，它的概率密度函数(或者随机变量X和Y的联合概率密度函数)：</p>

<script type="math/tex; mode=display">F(x,y)=\int_{-\infty}^{x_{i}}\int_{-\infty}^{y_{j}}f(u,v)dudv</script>

<p>二维连续性随机变量的性质：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/mul_3.png" alt="image" /></p>

<p>2.边缘分布</p>

<p>边缘分布函数，边缘分布律，边缘概率密度</p>

<p><strong>边缘分布其实就是指，对于一个多维随机变量来说，它具有一个联合分布律(或者联合概率密度)，但是如果我们只考虑它其中的某一个随机变量的话，那么这个随机变量的分布律(或者概率密度)就是边缘分布律(或者边缘概率密度)了。</strong></p>

<p>二维连续型随机变量(X,Y)对X的边缘概率密度实际上就是对y进行积分<script type="math/tex">f_{X}(x)=\int_{-\infty}^{\infty}f(x,y)dy</script>，同理，对Y的边缘概率密度实际上就是对x进行积分<script type="math/tex">f_{Y}(y)=\int_{-\infty}^{\infty}f(x,y)dx</script>。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cond_1.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/math/cond_2.png" alt="image" /></p>

<p>为什么叫边缘分布呢? 其实是因为一般边缘分布的数值写在联合分布律的表格边缘而已。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cond_3.png" alt="image" /></p>

<p>下面我们看下二维正态分布，这是一个很重要的多维随机变量分布，我们从中可以得到一些重要的结论。</p>

<p><strong>二维正态分布的两个边缘分布都是一维正态分布，给以这两个一维正态分布不同的参数会得到不同的二维正态分布，所以，已知关于X和Y的边缘分布，并不能确定X和Y的联合分布。</strong></p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cond_4.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/math/cond_5.png" alt="image" /></p>

<p>上面的参数$\rho$是随机变量X和Y的相关系数，后面还会详细介绍。</p>

<p>3.条件分布</p>

<p><strong>因为是多维随机变量，那么自然可以假定其中某一个随机变量为某个固定的值，在这种情况下我们再去看其他随机变量的分布那就是条件分布了。</strong></p>

<p>二维离散型随机变量的条件分布律</p>

<script type="math/tex; mode=display"> P(X=x_{i} \| Y=y_{j}) = \frac{P(X=x_{i},Y=y_{j})}{P(Y=y_{j})} </script>

<p><img src="http://hujiaweibujidao.github.io/images/math/cond_6.png" alt="image" /></p>

<p>二维连续型随机变量的条件概率密度</p>

<script type="math/tex; mode=display"> P(X=x_{i} \| Y=y_{j}) = \int_{-\infty}^{x}\frac{f(x,y)}{f_{Y}(y))}dx </script>

<p><img src="http://hujiaweibujidao.github.io/images/math/cond_8.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/math/cond_9.png" alt="image" /></p>

<p>举例说明连续型条件概率密度的计算</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cond_10.png" alt="image" /></p>

<p>4.相互独立的随机变量</p>

<p>前面我们提到随机变量之间可能存在相关性，那自然也有不存在相关性的随机变量，即相互独立的随机变量。很显然，如果随机变量(X,Y)的联合分布等于边缘分布的乘积那么就说明随机变量X和Y是相互独立的。</p>

<p>对于连续型随机变量(X,Y)来说，X和Y是相互独立的的条件是<script type="math/tex">f(x,y)=f_{X}(x)f_{Y}(y)</script>。</p>

<p>对于离散型随机变量(X,Y)来说，X和Y是相互独立的的条件是对于所有可能的<script type="math/tex">(x_{i},y_{j})</script>对，都有<script type="math/tex">P(X=x_{i},Y=y_{j})=P(X=x_{i})P(Y=y_{j})</script>。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/ind_2.png" alt="image" /></p>

<p>如果从期望和方差的角度来看独立性的话，那么就有<script type="math/tex">E(XY)=E(X)E(Y), D(X+Y)=D(X)+D(Y)</script>，也就是随机变量XY的期望是X和Y的期望的乘积，随机变量(X+Y)的方差是X和Y的方差之和。如果X和Y是相互独立的，那么它们的协方差Cov(X,Y)=0。</p>

<script type="math/tex; mode=display">E(XY)=\int_{-\infty}^{\infty}xyf(x)f(y)dxdy=\int_{-\infty}^{\infty}xyf_{X}(x)f_{Y}(y)dxdy=\int_{-\infty}^{\infty}xf_{X}(x)dx\int_{-\infty}^{\infty}yf_{Y}(y)dy=E(X)E(Y)</script>

<p>一般情况下，$D(X+Y)=D(X)+D(Y)+2Cov(X,Y)$，如果X和Y相互独立的话，Cov(X,Y)=0，则有$D(X+Y)=D(X)+D(Y)$。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/ind_4.png" alt="image" /></p>

<p>对于前面的二维正态随机变量，随机变量X和Y是相互独立的前提条件是它们的相关系数$\rho=0$(前面还证明过这个相关系数和X与Y的协方差相同，这就说明对于二维正态随机变量来说，它们的相关性和独立性是等价的，推广到n维正态随机变量也是如此)</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/ind_3.png" alt="image" /></p>

<p>二维随机变量中的独立性可以很容易地推广到n维随机变量上。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/ind_1.png" alt="image" /></p>

<p>5.随机变量函数的分布</p>

<p>有些时候我们需要处理的随机变量是几个随机变量形成的函数，这个时候它的分布是怎样的呢？
这类函数比较多，比如求和，乘积，商，最大值或者最小值，这里只说明其中最重要的一个和函数的分布。</p>

<p>从中我们得到一个结论：有限个相互独立的正态随机变量的线性组合仍然是服从正态分布。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/fun_1.png" alt="image" /></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-2/">http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-2/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SS 3-Continuous Distribution]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-1/"/>
    <updated>2014-05-19T20:30:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-1</id>
    <content type="html"><![CDATA[<p><strong><center>统计学那些事 Things of Statistics</center></strong>
<strong><center>逸夫图书馆, 2014/5/19</center></strong></p>

<hr />

<h4 id="center-center"><center>第三部分 分布之连续型随机变量分布</center></h4>

<p>连续型随机变量，概率密度及它的性质</p>

<p>函数f(x)是概率密度函数，函数F(x)是分布函数，两者都是连续函数。</p>

<script type="math/tex; mode=display">F(x)=\int_{-\infty}^{x}f(t)dt</script>

<p><a href="http://hujiaweibujidao.github.io/images/math/cont0.png">查看定义1</a>
<a href="http://hujiaweibujidao.github.io/images/math/cont1.png">查看定义2</a></p>

<p>关于连续型随机变量X对于任意一个指定实数值k的概率都是0，即$p(X=k)=0$的解释</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cont2.png" alt="image" /></p>

<p>(1)均匀分布(uniform distribution)</p>

<p>连续型随机变量X在区间(a,b)均匀分布，它的期望是$E=\frac{a+b}{2}$，也就是期望就是区间(a,b)的中点，它的方差是$D=\frac{(b-a)^{2}}{12}$，用$D=E(X^{2})-E^{2}$去证明方便些。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cont_uniform.png" alt="image" /></p>

<p>(2)指数分布(exponential distribution)</p>

<p>指数分布有一个参数$\theta$，它的期望就是$\theta$，方差是$\theta^{2}$，而且它具有<strong>无记忆性</strong>。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cont_exp1.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/math/cont_exp2.png" alt="image" /></p>

<p>证明它的期望是$\theta$，方差是$\theta^{2}$:</p>

<script type="math/tex; mode=display">E(X)=\int_{-\infty}^{\infty}xf(x)dx = \int_{0}^{\infty}x \frac{1}{\theta} e^{- \frac{x}{\theta}}dx = \int_{0}^{\infty}xd(-e^{- \frac{x}{\theta}}) = [-x e^{- \frac{x}{\theta}}]_{0}^{\infty} +  \int_{0}^{\infty} e^{- \frac{x}{\theta}}dx = \theta</script>

<script type="math/tex; mode=display">E(X^{2})=\int_{-\infty}^{\infty}x^{2}f(x)dx = \int_{0}^{\infty}x^{2} \frac{1}{\theta} e^{- \frac{x}{\theta}}dx = \int_{0}^{\infty}x^{2}d(-e^{- \frac{x}{\theta}}) = [-x^{2} e^{- \frac{x}{\theta}}]_{0}^{\infty} +  \int_{0}^{\infty} 2x e^{- \frac{x}{\theta}}dx = 2\theta^{2}</script>

<script type="math/tex; mode=display">D(X)=E(X^{2})-[E(X)]^{2}=\theta^{2}</script>

<p>《统计思维》对指数分布的解释：举例来说，<strong>观察一系列事件之间的间隔时间，若事件在每个时间点发生的概率相同，那么间隔时间的分布就近似指数分布</strong>(也就是前面的无记忆性)。</p>

<p>指数分布的CDF如下，此时$\lambda=\frac{1}{\theta}$</p>

<script type="math/tex; mode=display">
CDF(x)=1-e^{-\lambda x}
</script>

<p>参数$\lambda$决定了指数分布的形状，通常，指数分布的均值是$\frac{1}{\lambda}$，中位数是$\frac{log(2)}{\lambda}$。下图为$\lambda=2$的指数分布图：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/edcdf.png" alt="image" /></p>

<p>如何判断一个分布是否是指数分布呢？一种办法是画出取对数之后的互补累积分布函数(CCDF=Complementary CDF=1-CDF(x))，CCDF是一条斜率为$-\lambda$的直线，原因如下：</p>

<script type="math/tex; mode=display">
y=CCDF(x)=1-CDF(x)=e^{-\lambda x} \quad => \quad log(y)=-\lambda x
</script>

<p>(3)正态分布(normal distribution)</p>

<p>正态分布，又叫高斯分布，是最常用的分布。其中$x=\mu$是函数f(x)的驻点，$x=\mu+\sigma,  x=\mu-\sigma$是函数f(x)的拐点，这个可能不太好计算，可用下面的Matlab代码进行验证。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="n">clear</span><span class="p">,</span><span class="n">clc</span><span class="p">;</span>
</span><span class="line"><span class="n">syms</span> <span class="n">x</span><span class="p">;</span>
</span><span class="line"><span class="n">syms</span> <span class="n">u</span><span class="p">;</span>
</span><span class="line"><span class="n">syms</span> <span class="n">r</span><span class="p">;</span>
</span><span class="line"><span class="n">syms</span> <span class="n">p</span><span class="p">;</span>
</span><span class="line"><span class="n">f</span><span class="p">=</span>1 <span class="o">/</span> <span class="p">(</span><span class="nb">sqrt</span><span class="p">(</span>2<span class="o">*</span><span class="n">p</span><span class="p">)</span><span class="o">*</span><span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="nb">exp</span><span class="p">(</span><span class="o">-</span>1 <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">u</span><span class="p">)</span>^2 <span class="o">/</span> <span class="p">(</span>2<span class="o">*</span><span class="n">r</span>^2<span class="p">)</span> <span class="p">);</span>
</span><span class="line"><span class="n">pretty</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span><span class="line"><span class="n">f1</span><span class="p">=</span><span class="n">diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> 1<span class="p">)</span> <span class="c">%一阶导数</span>
</span><span class="line"><span class="n">pretty</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
</span><span class="line"><span class="n">f2</span><span class="p">=</span><span class="n">diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> 2<span class="p">)</span> <span class="c">%二阶导数</span>
</span><span class="line"><span class="n">pretty</span><span class="p">(</span><span class="n">f2</span><span class="p">)</span>
</span><span class="line"><span class="n">solve</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span> <span class="c">%u</span>
</span><span class="line"><span class="n">solve</span><span class="p">(</span><span class="n">f2</span><span class="p">)</span> <span class="c">%u+r u-r</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="http://hujiaweibujidao.github.io/images/math/cont_normal1.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/math/cont_normal2.png" alt="image" /></p>

<p>关于标准正态分布，即参数为$\mu=0, \sigma=1$的正态分布，它的分布函数值已经制作成表格，可以方便进行查看，其他非标准正态分布可以通过一个线性变换转换成标准正态分布。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cont_normal4.png" alt="image" /></p>

<p>在证明其概率密度总和为1时利用了一个重要的积分$\int_{-\infty}^{\infty} e^{\frac{t^{2}}{2}} dt = \sqrt{2 \pi}$，它的证明可以转换成二重积分然后通过极坐标计算出来。完整详细的证明可以参考下面：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/inte1.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/math/inte2.png" alt="image" /></p>

<p>《统计思维》对正态分布的解释：对于正态分布的CDF还没有一种准确的表达，最常用的一种形式是以误差函数(error function)来表示，它是一个特殊的函数，表示为erf(x)，在Matlab中内置了函数<code>erf</code>，对它的说明为erf函数是对参数为$\mu=0, \sigma=\frac{1}{2}$的正态分布的二重积分，有兴趣可以去计算一下，得到的结果如下：</p>

<script type="math/tex; mode=display">
CDF(x)=\frac{1}{2}[1+erf(\frac{x-\mu}{\sigma \sqrt{2}})] \quad erf(x)=\frac{2}{\sqrt{\pi}}\int_{0}^{x}e^{-t^{2}}dt
</script>

<p>其中，参数$\mu$和$\sigma$分别决定了正态分布的均值和标准差。下图为$\mu=2.0$和$\sigma=0.5$的正态分布的CDF图：[呈现明显的S型]</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/ndcdf.png" alt="image" /></p>

<p>根据大数定理，当我们处理大样本数据集(超过30个数据)，并且重复地从总体中抽取样本时，得到的数值分布就接近正态分布曲线。正态分布以均值为中心完全对称。</p>

<p>关于正态分布有一个重要的结论，对任何数值分布来说(不论它的均值和标准差)，只要数值是正态分布，那么几乎100%的数值都分布在均值的-3到3个标准差之间。下面是正态曲线下数值的分布情况：</p>

<!--
![image](http://hujiaweibujidao.github.io/images/math/nd.png)
-->

<p><img src="http://hujiaweibujidao.github.io/images/math/cont_normal3.png" alt="image" /></p>

<p>从中可以看出，<strong>在距离均值1个标准差之间大概有34%的数值分布，在1个标准差和2个标准差之间大概有13%的数值分布，在2个标准差和3个标准差之间大概有2.1%的数值分布。</strong></p>

<p>通过这个图我么可以得到一个经典的<strong>3$\sigma$法则</strong>，又叫<strong>68-95-99法则</strong></p>

<p><strong>在$(\mu - \sigma, \mu + \sigma)$之间大概有68.26%的数据分布，在$(\mu - 2\sigma, \mu + 2\sigma)$之间大概有95.44%的数据分布，在$(\mu - 3\sigma, \mu + 3\sigma)$之间大概有99.74%的数据分布。</strong></p>

<p>$\alpha$分位点的概念：对于标准正态分布X~N(0,1)，满足<script type="math/tex">P(X>Z_{\alpha})=\alpha</script>的<script type="math/tex">Z_{\alpha}</script>称为$\alpha$分位点，且有<script type="math/tex">Z_{-1\alpha}=Z_{\alpha}</script>。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cont_normal5.png" alt="image" /></p>

<p><a href="http://wikipedia.org/wiki/Log-normal_distribution">对数正态分布 on wiki</a>：如果一组数据取对数之后服从正态分布，那么我们就称其服从对数正态分布。对数正态分布的 CDF 跟正态分布一样, 只是用 logx 代替原来的 x:</p>

<script type="math/tex; mode=display">
CDF_{lognormal}(x) = CDF_{normal}(log x)
</script>

<p>对数正态分布的均值与标准差不再是是$\mu$和$\sigma$了。可以证明，成人体重的分布是近似对数正态的。</p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-1/">http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-1/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SS 3-Discrete Distribution]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2/"/>
    <updated>2014-05-19T20:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2</id>
    <content type="html"><![CDATA[<p><strong><center>统计学那些事 Things of Statistics</center></strong>
<strong><center>逸夫图书馆, 2014/5/19</center></strong></p>

<hr />

<h4 id="center-center"><center>第三部分 分布之离散型随机变量分布</center></h4>

<p>1.概率质量函数PMF(Probability Mass Function)</p>

<p>数据集的数据值到它的概率的映射函数。直方图是各个值出现的频数，如果将频数除以样本总数，得到概率，归一化之后的直方图就是PMF。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/pmf.png" alt="image" /></p>

<p>2.累积分布函数CDF(Cumulative Distribution Function)</p>

<p>数据集的数据值到它在分布中概率的累积值的映射函数。PMF和CDF在国内的教材中并没有这样提过，但是在国外的很多统计书中都有，所以还是比较重要的，拿出来介绍下。</p>

<p>例如，CDF(0) = 0; CDF(1) = 0.2; CDF(2) = 0.6; CDF(3) = 0.8; CDF(4) = 0.8; CDF(5) = 1，它的CDF图为一个阶跃函数：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cdf.png" alt="image" /></p>

<p>3.离散型随机变量及其分布律</p>

<p>分布律：离散型随机变量以概率1和一定的规律分布在一些离散值上</p>

<p><a href="http://hujiaweibujidao.github.io/images/math/disc0.png">查看定义</a></p>

<p>(1)0-1分布</p>

<p>随机变量X只有两个取值0和1(样本空间只有两个取值也行)，所以叫做0-1分布，它的分布律为
$P(X=0)=p, P(X=1)=q, (q=1-p)$，它的期望是$p$，方差是$p(1-p)$。</p>

<p><a href="http://hujiaweibujidao.github.io/images/math/disc_01.png">查看定义</a></p>

<p>(2)二项分布</p>

<p>二项分布的分布律为 $P(X=k)= {n \choose k} p^{k}q^{1-k}$，因为 $P(X=k)$ 刚好是 $(p+q)^{n}$ 的二项式系数，所以这个分布就叫二项分布。二项分布是从n重伯努利试验中得到的分布，所谓的伯努利试验就是指相互独立的试验，每次试验的结果要么成功要么失败(或者说某个事件要么发生要么不发生)。</p>

<p><a href="http://hujiaweibujidao.github.io/images/math/disc_binomial.png">查看定义1</a>
<a href="http://hujiaweibujidao.github.io/images/math/disc_binomial2.png">查看定义2</a></p>

<p>(3)泊松分布</p>

<p>泊松分布是一类很常用的分布，它的分布律是$P(X=k)=\frac{\lambda^{k} e^{-\lambda}}{k!},(k=0,1,2,…)$，其中有一个参数$\lambda$，参数$\lambda$的含义既是泊松分布的期望，又是它的方差，所以，只要参数$\lambda$或者期望或者方差确定了，泊松分布就确定了。泊松分布中经常需要用到的式子[$e^{\lambda}=\Sigma_{k=0}^{\infty}\frac{x^{k}}{k!}$]</p>

<p><a href="http://hujiaweibujidao.github.io/images/math/disc_pos.png">查看定义</a></p>

<p>证明它的期望是$\lambda$: </p>

<script type="math/tex; mode=display">E=\Sigma_{k=0}^{\infty}k \frac{\lambda^{k} e^{-\lambda}}{k!}=\lambda e^{-\lambda} \Sigma_{k=1}^{\infty} \frac{\lambda^{k-1}}{(k-1)!}=\lambda e^{-\lambda} e^{\lambda}=\lambda</script>

<p>证明它的方差是$\lambda$:</p>

<script type="math/tex; mode=display">D=E(X^{2})-E^{2}=E(X(X-1)-X)-E^{2}=\Sigma_{k=0}^{\infty}k(k-1) \frac{\lambda^{k} e^{-\lambda}}{k!}+\lambda-\lambda^{2}=\lambda e^{-\lambda} \Sigma_{k=1}^{\infty} \frac{\lambda^{k-1}}{(k-1)!}=\lambda^{2} e^{-\lambda} e^{\lambda}+\lambda-\lambda^{2}=\lambda</script>

<p><strong>泊松定理说明当n很大，p很小的时候，以n，p为参数的二项分布可以用参数$\lambda = np $的泊松分布进行近似！</strong>记住这个定理其实也可以方便我们记住泊松分布的分布律。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/disc_pos2.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/math/disc_pos3.png" alt="image" /></p>

<p>应用举例，记住后面的结论：</p>

<p><strong>当$n \ge 20,p \le 0.05$时用泊松分布近似二项分布的概率值近似效果颇佳。</strong></p>

<p><img src="http://hujiaweibujidao.github.io/images/math/disc_pos4.png" alt="image" /></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2/">http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SS 2-Covariance and Correlation coefficient]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-3/"/>
    <updated>2014-05-19T19:30:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-3</id>
    <content type="html"><![CDATA[<p><strong><center>统计学那些事 Things of Statistics</center></strong>
<strong><center>逸夫图书馆, 2014/5/19</center></strong></p>

<hr />

<h4 id="center-center"><center>第二部分 协方差和相关关系</center></h4>

<p>1.协方差</p>

<p>随机变量X和Y的协方差Cov(X,Y)=E[X-E(X)]E[Y-E(Y)]=E(XY)-E(X)E(Y)。</p>

<p>为什么D(X+Y)=E(XY)-E(X)E(Y)?</p>

<script type="math/tex; mode=display">
D(X+Y)=E[(X+Y)^{2}]-[E(X+Y)]^{2}=E[X^{2}+Y^{2}-2XY]-[E(X)+E(Y)]^{2} \\ =E[X^{2}]-[E(X)]^{2}+E[Y^{2}]-[E(Y)]^{2}+2E(XY)-2E(X)E(Y) \\ =D(X)+D(Y)+2E(XY)-2E(X)E(Y)
</script>

<p>因为 <strong>(X+Y)=D(X)+D(Y)+2Cov(X,Y)</strong>
所以 <strong>D(X+Y)=E(XY)-E(X)E(Y)</strong></p>

<p>协方差的性质：(基本上根据上式都可以简单证明得到)</p>

<p>Cov(X,Y)=Cov(Y,X)， Cov(X,X)=D(X)，Cov(aX,bY)=abCov(X,Y)，<script type="math/tex">Cov(X_{1}+X_{2},Y)=Cov(X_{1},Y)+Cov(X_{2},Y)</script></p>

<p>如果X和Y是相互独立的，那么Cov(X,Y)=0。</p>

<p>2.相关系数(correlation coefficient)是两个变量之间<strong>线性关系</strong>的数值型指标，取值范围是[-1,1]，大于0表示正相关，小于0表示负相关，可以用散点图来直接查看相关性。<strong>根据某些不成文的规则，一般高于0.6表示强相关，低于0.4表示弱相关，中间部分表示中度相关。</strong></p>

<p>[<strong>一般说的相关系数是Pearson相关系数，它考察的变量的属性是连续的，例如年龄，体重等，如果是离散型变量那么应该使用点二列相关系数</strong>]</p>

<p>相关系数的计算，我们经常可以看到下面两种表示方式：</p>

<p>一种表示方式是：[这是从协方差和方差的角度来看的]</p>

<script type="math/tex; mode=display">
\rho_{XY}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}
</script>

<p>还有一种常见的表示方式是：[这是从数据本身来看的]</p>

<script type="math/tex; mode=display">
r_{XY}=\frac{n\Sigma{XY}-\Sigma{X}\Sigma{Y}}{\sqrt{[n\Sigma{X^2}-(\Sigma{X})^2][n\Sigma{Y^2}-(\Sigma{Y})^2]}}
</script>

<p>其实，很容易看出两者是等价的，因为$E(X)=\frac{\Sigma X}{n}, D(X)=\frac{\Sigma X^{2}}{n} - \frac{\Sigma X}{n^{2}}$，然后将第二个等式右边上下除以$n^{2}$即可得到第一个等式的右边。</p>

<p>举个计算的例子：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cor_1.png" alt="image" /></p>

<p>得到的结果为0.692，算是一个强相关</p>

<script type="math/tex; mode=display">
r_{XY}=\frac{10 \times 247-54 \times 43}{\sqrt{[10 \times 320-(54)^2][10 \times 201-(43)^2]}} = 0.692
</script>

<p>为什么说相关系数反映的只是随机变量之间的线性关系呢？</p>

<p>我们总是用关于X的线性函数a+bX去近似Y，也就是用直线a+bX去拟合Y，如何判断拟合的好坏呢？一般都是用均方误差，也就是误差值的平方的均值，然后用均方误差对a和b分别求导即可得到使得均方误差达到最小的拟合参数a和b。很有意思的一个结论就是，<strong>均值点(E(X),E(Y))一定在拟合直线a+bX上</strong>。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cor_2.png" alt="image" /></p>

<p>最后得到的结果是:<script type="math/tex">min E[(Y-(a+bX))^{2}]=(1-\rho_{XY}^{2})D(Y)</script>，从中可以得到很多性质：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cor_3.png" alt="image" /></p>

<table>
  <tbody>
    <tr>
      <td>均方误差e和相关系数$\rho$之间的关系，e是$$</td>
      <td>\rho_{XY}</td>
      <td>$$的严格单调递减函数。</td>
    </tr>
  </tbody>
</table>

<p><img src="http://hujiaweibujidao.github.io/images/math/cor_4.png" alt="image" /></p>

<p>注意两点：</p>

<p>(1)<strong>相关系数反映的是只是线性关系！如果两个变量的相关系数为0，只能说明它们没有线性关系存在，但是可能存在其他的非线性关系！不相关和相互独立是不一样的，不相关只是就线性关系来说，相互独立是就一般关系而言。</strong></p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cor_5.png" alt="image" /></p>

<p>但是，有时候相关性和独立性是等价的，比如下面的二维正态分布，这是很重要的多维随机变量分布，随机变量X和Y相互独立的条件是$\rho=0$(不明白可以看下节对多维随机变量分布的介绍)，而$\rho$正好等于<script type="math/tex">\rho_{XY}</script>，且随机变量X和Y不相关的条件就是<script type="math/tex">\rho_{XY}=0</script>，所以此时相关性和独立性是等价的。[之后我会写一篇文章并通过作图的方式介绍相关系数到底是如何影响二维正态分布的数据的分布的]</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/cor_6.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/math/cor_7.png" alt="image" /></p>

<p>(2)<strong>相关性和因果关系无关！</strong>例如，冰淇淋的消费量和犯罪率是正相关的(可以参考《爱上统计学》)，但是两者不存在任何因果关系！</p>

<p>决定系数：相关系数的平方，它表述一个变量的方差可以被另一个变量的方差来解释的百分比。(参考《爱上统计学》)</p>

<p>3.协方差矩阵</p>

<p>协方差矩阵是非常重要的内容，经典算法PCA的基础就是协方差矩阵。引入它之前，先要看下原点矩和中心距的概念</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/corm_1.png" alt="image" /></p>

<p>协方差矩阵其实就是由n维随机变量之间两两的二阶混合中心距组成的矩阵</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/corm_2.png" alt="image" /></p>

<p>还是回到我们最重要的那个二维正态随机变量，看下如何将它的概率密度转换成协方差矩阵的表示形式，继而将其推广至n维正态随机变量。</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/corm_5.png" alt="image" />
<img src="http://hujiaweibujidao.github.io/images/math/corm_4.png" alt="image" /></p>

<p>上面最后得到的n维正态随机变量的概率密度公式是在模式识别里面非常重要的，n维正态随机变量的性质如下：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/corm_3.png" alt="image" /></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-3/">http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-3/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SS 1-Probability and Descriptive Statistics]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-1/"/>
    <updated>2014-05-19T19:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-1</id>
    <content type="html"><![CDATA[<p><strong><center>统计学那些事 Things of Statistics</center></strong>
<strong><center>逸夫图书馆, 2014/5/19</center></strong></p>

<hr />

<h4 id="center-center"><center>第一部分 概率和统计量</center></h4>
<p>1.事件：对立事件(complementary event)，互斥事件(exclusive event)，相交事件(intersecting event)，相关事件(dependent event)，独立事件(independent event)，可以使用韦恩图(Venn Diagram)方便分析事件之间的关系。</p>

<p>如果事件A和B会相互影响，那么它们是相关事件，否则是独立事件。
事件A和B独立：$P(A|B)=P(A) \quad P(A \cap B)=P(A)P(B)$</p>

<p>2.概率：条件概率(Conditional Probability)，全概率(Total Probability)，贝叶斯定理(Bayes’ Theorem)</p>

<p>条件概率：$ P(A | B) = \frac{P(A \cap B)}{P(B)} $</p>

<p>全概率：$ P(B) = P(B | A) P(A)+P(B | A’) P(A’) $</p>

<p>贝叶斯定理(将条件概率和全概率整合到一起)：
$P(A|B)=\frac{P(A \cap B)}{P(B|A)P(A)+P(B|A’)P(A’)}$</p>

<p>3.描述数据的集中趋势：均值(mean)，中位数(median)，众数(mode)，加权平均数</p>

<p>百分位点(percentile points)：中位数(Q2)就是50百分位点，Q1为25百分位点(lower quartile)，Q3为75百分位点(upper quartile)，<strong>经常使用Q3-Q1=IQR(interquartile range，四分差或四分位数)来检查分布是否对称。</strong></p>

<!--
[如果要计算一组数中的某个百分位数，一般比较好的排序方法是选择排序；当然，如果是计算该组数的特殊的百分位数，例如中位数，有其他更好地方法能够在线性时间内得到，之后我对做一些相关问题的研究，暂且说明一下]
-->

<p>4.描述数据的变异性：极差(range)，标准差(standard deviation,简称s或者SD)，方差(deviation)</p>

<p>标准差的计算公式：
$$
s=\sqrt{\frac{\Sigma(X-\bar{X})^2}{n-1}}
$$</p>

<p><strong>s是总体标准差的无偏估计，如果根号内部分母改成了n则是有偏估计，详细证明参见：<a href="http://en.wikipedia.org/wiki/Bias_of_an_estimator">Bias_of_an_estimator</a>，《爱上统计学》作者对此的解释是统计学家们通常比较保守，保守的含义是，如果我们不得不出错，我们出错也是因为过高地估计了标准差(因为除以n-1使得标准差大于实际值)。</strong></p>

<p>如果想了解更加细致的内容可以看下这篇文章<a href="http://www.visiondummy.com/2014/03/divide-variance-n-1/">Why divide the sample variance by N-1?</a></p>

<p>标准差和方差的异同：<strong>它们都是用来反映数据集的数据的变异性或者离散度的度量，但是标准差以原有的计算单位存在，然而方差以平方单位存在，前者在实际中更加具有意义</strong>。例如，某高校的男生的平均身高是170cm，标准差是5cm，那么说明该校男生的身高与平均身高的差异大概就是上下5cm，换成方差来解释的话就不好陈述了。</p>

<p>使用有偏估计其实也可以，但是最好使用无偏估计，我记得Coursera上Machine Learning课中Andrew Ng曾经提到过，实际编码中其实还是使用有偏估计，因为它们在样本数据很大的时候其实结果没多大影响。</p>

<p>5.数据集的图形化显示：直方图，饼图，线图，柱形图，条形图，茎叶图等</p>

<p>数据分布的差异性描述：平均值，变异性，峰度(kurtosis)，偏度(skewness)</p>

<p>峰值可能有多个，比如双峰或者多峰等。偏度有一个计算公式，由Pearson发明的，他同时也是相关系数的发明者，偏度虽有正负之分，但是绝对值越大说明图形越偏。</p>

<script type="math/tex; mode=display">
SK=\frac{3(\bar{X}-M)}{s},\quad M=Median,\bar{X}=Mean,s=SD
</script>

<p>峰度图：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/kurtosis.png" alt="image" /></p>

<p>偏度图：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/skewness.png" alt="image" /></p>

<p>6.两个最重要的统计量：期望(Expectation)与方差(Variance)</p>

<p>$E(x)=\Sigma xP(X=x)=\mu \quad Var(x)=E(x-\mu)^{2}=\Sigma (x-\mu)^2P(X=x)=E(x^{2})-(E(x))^{2}$</p>

<p>[注：上面的期望的等式是对于离散型随机变量x，如果是连续型随机变量x，那么<script type="math/tex">E=\int_{-\infty}^{\infty} xf(x)dx</script>，同理，方差就是<script type="math/tex">D=\int_{-\infty}^{\infty} (x-E)^{2}f(x)dx</script>，期望描述的是数据的集中趋势，方差描述的数据的偏移程度]</p>

<p>线性变换之后的期望与方差：</p>

<p>$E(ax+b)=aE(x)+b \quad Var(ax+b)=a^{2}Var(x)$
$E(ax+by)=aE(x)+bE(y) \quad Var(ax+by)=a^{2}Var(x)+b^{2}Var(y)$</p>

<p><strong>思考：为什么加上b，方差并没有发生变化呢？</strong></p>

<p><strong>因为在变量中增加常数b只是将概率分布移动了一下，分布的形状并没有发生改变，所以b并没有在方差中起到作用。</strong></p>

<p>相互独立事件X和Y(或者说是随机变量X和Y)：</p>

<p>$E(X+Y)=E(X)+E(Y) \quad Var(X+Y)=Var(X)+Var(Y)$
$E(X-Y)=E(X)-E(Y) \quad Var(X-Y)=Var(X)+Var(Y)$</p>

<p><strong>思考：为什么$Var(X-Y)=Var(X)+Var(Y)$？</strong></p>

<script type="math/tex; mode=display">Var(X-Y)=E[(X-Y)^{2}]-[E(X-Y)]^{2}=E(X^{2})+E(Y^{2})-2E(X)E(Y)+[E(X)-E(Y)]^{2}\\
=E(X^{2})-[E(X)]^{2}+E(Y^{2})-[E(Y)]^{2}-2E(X)E(Y)+2E(X)E(Y)=Var(X)+Var(Y)</script>

<p><strong>记住，一个随机变量减去另一个随机变量得到的概率分布的方差是两个随机变量的方差之和，方差只会增加！</strong></p>

<p>下面两个图示演示了其结果</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/varxplusy.png" alt="image" /></p>

<p><img src="http://hujiaweibujidao.github.io/images/math/varxminusy.png" alt="image" /></p>

<p>相互独立的随机变量与独立观测值之间的区别：</p>

<p><img src="http://hujiaweibujidao.github.io/images/math/independentobservation.png" alt="image" /></p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-1/">http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-1/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Statistics Summary]]></title>
    <link href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary/"/>
    <updated>2014-05-19T18:00:00+08:00</updated>
    <id>http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary</id>
    <content type="html"><![CDATA[<p><strong><center>统计学那些事 Things of Statistics</center></strong>
<strong><center>逸夫图书馆, 2014/5/19</center></strong></p>

<hr />

<h4 id="center-center"><center>第零部分 碎碎念</center></h4>
<p>本系列是对概率和数理统计中的重要内容的一个总结，不会侧重很多众所周知的细节，所以有啥疑问还是需要Google或者Wikipedia。关于本系列中出现的术语参照参考书籍中的定义，部分可能与大学教材中不同，请自行对应起来理解。小弟才疏学浅，若有错误请留言，欢迎批评指正。</p>

<p>参考书籍：</p>

<p>1.<a href="http://book.douban.com/subject/2985995/">《爱上统计学》</a></p>

<p>2.<a href="http://book.douban.com/subject/7056708/">《深入浅出统计学》</a></p>

<p>3.<a href="http://book.douban.com/subject/24381562/">《统计思维：程序员数学之概率统计》</a></p>

<p>4.<a href="http://book.douban.com/subject/3165271/">《概率论与数理统计》</a></p>

<p>全部内容：</p>

<p>1.<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-1/">概率和统计量</a></p>

<p>2.<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-3/">协方差和相关关系</a></p>

<p>3.随机变量的分布</p>

<p>(1)<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2/">分布之离散型随机变量分布</a></p>

<p>(2)<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-1/">分布之连续型随机变量分布</a></p>

<p>(3)<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-2-2/">分布之多维随机变量及其分布</a></p>

<p>4.<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary-4/">假设检验</a></p>

<p>To do list: 显著性检验，ANOVA……</p>

<p>[To be Continued…]</p>

<p class="post-footer">
                        Original link:<a href="http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary/">http://hujiaweibujidao.github.io/blog/2014/05/19/statistics-summary/</a><br />Written by <a href="http://hujiaweibujidao.github.io">hujiawei</a>&nbsp;Posted at <a href="http://hujiaweibujidao.github.io">http://hujiaweibujidao.github.io</a><br />Feel free to read or comment it, and if you want to copy it into your own site, please copy it with its Original Link showed above or you can see the license below for more details.If you have any problem or suggestion, please comment below. :-)<br />Thanks a lot. Hope you enjoy here! :-)</p>
]]></content>
  </entry>
  
</feed>
